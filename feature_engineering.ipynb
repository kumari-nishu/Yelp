{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_acquisition.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import import_ipynb\n",
    "import data_acquisition\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Invoke Data Acquisition Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yelp_data():\n",
    "    # invoking data acquisition functions\n",
    "    ratings = data_acquisition.get_ratings_data()\n",
    "    business = data_acquisition.get_business_data()\n",
    "    checkin = data_acquisition.get_checkin_data()\n",
    "    user = data_acquisition.get_user_data()\n",
    "    tips = data_acquisition.get_tips_data()\n",
    "    \n",
    "    return ratings, business, checkin, user, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_features(user, ratings, tips):\n",
    "    active_users = pickle.load(open(\"data/active_users_list.pkl\", \"rb\"))\n",
    "    active_users = active_users[0].values.tolist()\n",
    "    \n",
    "    # subsetting for active users\n",
    "    user = user[user.user_id.isin(active_users)]\n",
    "    \n",
    "    # for each user, date of last review and total tips provided\n",
    "    last_user_review = ratings.groupby(['user_id'], sort = False)['date'].max().reset_index()\n",
    "    user_tips_count = tips.groupby(['user_id'], sort = False)['compliment_count'].sum().reset_index()\n",
    "\n",
    "    user = user.replace('',np.nan)\n",
    "\n",
    "    # create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()    \n",
    "\n",
    "    #1. normalizing review attributes    \n",
    "    review_norm_mdl = min_max_scaler.fit(user[['review_count']])\n",
    "    user['review_count_norm'] = pd.DataFrame(review_norm_mdl.transform(user[['review_count']])) \n",
    "\n",
    "    #2. compliments per review count\n",
    "    for col in user.columns[7:17]:\n",
    "        user[col] = user[col]/user['review_count']\n",
    "        \n",
    "    user['compliment_score'] = 0\n",
    "    for col in user.columns[7:17]:\n",
    "        user['compliment_score'] += user[col]\n",
    "        \n",
    "    compliment_columns = ['compliment_hot', 'compliment_more', 'compliment_profile', 'compliment_cute', \n",
    "                          'compliment_list', 'compliment_note', 'compliment_plain', 'compliment_cool', \n",
    "                          'compliment_funny', 'compliment_writer', 'compliment_photos']\n",
    "    user.drop(columns = compliment_columns, axis = 1, inplace = True)\n",
    "\n",
    "    #3. total friends for each user normalized\n",
    "    user['friends'] = user['friends'].apply(lambda x : len(x.split(','))) \n",
    "    friends_norm_mdl = min_max_scaler.fit(user[['friends']])\n",
    "    user['friends_norm'] = pd.DataFrame(friends_norm_mdl.transform(user[['friends']])) \n",
    "\n",
    "    #4. total elite years for each user\n",
    "    def elite_count(x):\n",
    "        year = str(x).split(',')\n",
    "        if year[0] == 'nan':\n",
    "            year_count = 0\n",
    "        else:\n",
    "            year_count = len(year)  \n",
    "        return year_count, year\n",
    "\n",
    "    user['elite_intm'] = user['elite'].apply(lambda x : elite_count(x))\n",
    "    user['elite_count'] = [x[0] for x in user['elite_intm']]\n",
    "\n",
    "    #5. yelping since number of days\n",
    "    user['yelping_since'] = (pd.to_datetime(user['yelping_since'])).dt.normalize()\n",
    "    user = user.merge(last_user_review, on = 'user_id', how = 'left')\n",
    "    user['date'] = pd.to_datetime(user['date'], errors = 'ignore', format = '%Y-%m-%d %H:%M:%S')\n",
    "    user['user_lifetime'] = (user['date'] - user['yelping_since']).apply(lambda x: x.days)\n",
    "\n",
    "    #6. tip count normalized for each user\n",
    "    user = user.merge(user_tips_count, on = 'user_id', how = 'left')\n",
    "    user['compliment_count'] = user['compliment_count']/user['review_count']\n",
    "\n",
    "    #7. total fans of each user normalized\n",
    "    fans_norm_mdl = min_max_scaler.fit(user[['fans']])\n",
    "    user['fans_norm'] = pd.DataFrame(fans_norm_mdl.transform(user[['fans']])) \n",
    "\n",
    "    # removing user features not needed\n",
    "    user.drop(['friends', 'fans' , 'yelping_since', 'elite', 'elite_intm', 'date'], axis = 1, inplace = True)\n",
    "    user = user.drop_duplicates()\n",
    "    user = user.fillna(0)\n",
    "    \n",
    "    user.to_pickle(\"data/user_feature_set.pkl\")\n",
    "    return user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define Business Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item_features(business, checkin):\n",
    "    # sampling for Las Vegas businesses that are open\n",
    "    business = business[business['is_open'] == 1]\n",
    "    business = business[business['city'] == 'Las Vegas']\n",
    "    \n",
    "    # creating a list for hours of business each day\n",
    "    business['hours'] = business['hours'].apply(lambda x: ' '.join(' '.join(str(x).split(', ')).split(': ')).split())\n",
    "    business.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    # considering only 'Restaurants' business category\n",
    "    for i in tqdm(range(len(business))):\n",
    "        category_string = str(business.loc[i, 'categories'])\n",
    "        if category_string.find('Restaurants') >= 0:\n",
    "            business.loc[i, 'is_restaurant'] = 1\n",
    "    \n",
    "    business = business[business.is_restaurant == 1]\n",
    "    business.reset_index(inplace = True, drop = True)\n",
    "    \n",
    "    all_categories = []\n",
    "    for i in tqdm(range(len(business))):\n",
    "        # maintain list of all business categories\n",
    "        all_categories.extend(business.loc[i, 'categories'])\n",
    "\n",
    "        if business.loc[i, 'hours'] == ['None'] or []:\n",
    "            business.loc[i, 'total_hours'] = 0\n",
    "        else:\n",
    "            open_hours = business.loc[i, 'hours'][1::2]\n",
    "            open_hours[-1] = open_hours[-1][:-1]\n",
    "            open_hours = [x[1:len(x)-1].split('-') for x in open_hours]\n",
    "            total_hours = 0\n",
    "            \n",
    "            # computing total hours open per week for each business\n",
    "            for j in range(len(open_hours)):\n",
    "                delta = datetime.strptime(open_hours[j][1], '%H:%M') - datetime.strptime(open_hours[j][0], '%H:%M')\n",
    "                if delta <= timedelta(days = -1, hours = 23):\n",
    "                    delta = delta - timedelta(days=-1)\n",
    "\n",
    "                delta = delta.seconds//3600\n",
    "                total_hours = total_hours + delta\n",
    "            business.loc[i, 'total_hours'] = total_hours\n",
    "            \n",
    "    # subset for 10 most common business categories by count\n",
    "    top10_categories = Counter(all_categories).most_common(10)\n",
    "    category_name = [category for category, count in top10_categories]\n",
    "\n",
    "    business.drop(['is_restaurant'], axis = 1, inplace = True)\n",
    "    business['str_categories'] = business['categories'].apply(lambda x : str(x))\n",
    "\n",
    "    # one-hot encoding to indicate presence of top 10 category for each business\n",
    "    for category in tqdm(category_name):\n",
    "        category_presence = [category_list for category_list in business['categories'] if category in category_list]\n",
    "        category_features = pd.DataFrame(0, index = range(0, len(category_presence)), columns = [category,'presence'])\n",
    "        for i in range(len(category_presence)):\n",
    "            category_features.loc[i, category] = str(category_presence[i])\n",
    "            category_features.loc[i, 'presence'] = 1\n",
    "\n",
    "        category_features = category_features.rename(columns={category: \"str_categories\"})\n",
    "        category_features['str_categories'] = category_features['str_categories'].apply(lambda x : str(x))    \n",
    "        category_features = category_features.drop_duplicates()\n",
    "\n",
    "        business = business.merge(category_features, how = \"left\", on = \"str_categories\")\n",
    "        business = business.rename(columns={\"presence\": category})\n",
    "    \n",
    "    business.drop(['city', 'categories', 'hours', 'str_categories', 'is_open'], axis = 1, inplace = True)\n",
    "    \n",
    "    # finding first, last and total checkins for each business\n",
    "    checkin['total_checkins'] = checkin['date'].apply(lambda x: len(str(x).split(', ')))\n",
    "    checkin['last_checkin'] = checkin['date'].apply(lambda x: max(str(x).split(', ')))\n",
    "    checkin['first_checkin'] = checkin['date'].apply(lambda x: min(str(x).split(', ')))\n",
    "\n",
    "    last_checkin = pd.to_datetime(checkin['last_checkin'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    first_checkin = pd.to_datetime(checkin['first_checkin'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # computing age of business in terms of first and last checkin\n",
    "    checkin['age_of_business'] = (last_checkin - first_checkin).apply(lambda x: x.days)\n",
    "    checkin.drop(['date', 'first_checkin', 'last_checkin'], axis = 1, inplace = True)\n",
    "\n",
    "    business = business.merge(checkin, how = 'left', on = 'business_id')\n",
    "    business = business.drop_duplicates()\n",
    "    business = business.fillna(0)\n",
    "    \n",
    "    business.to_pickle(\"data/business_feature_set.pkl\")\n",
    "    return business"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Map User & Business Features to Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_ratings(ratings, user, business):\n",
    "    # imputing user and business attributes to ratings\n",
    "    ratings = ratings.merge(user, on = 'user_id')\n",
    "    ratings = ratings.merge(business, on = 'business_id')\n",
    "    \n",
    "    # subsetting active businesses based on >=5 ratings\n",
    "    business_ratings_count = ratings['business_id'].value_counts()\n",
    "    active_business = business_ratings_count.loc[business_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.business_id.isin(active_business)]\n",
    "    \n",
    "    # subsetting active users based on >=5 ratings\n",
    "    user_ratings_count = ratings['user_id'].value_counts()\n",
    "    active_users = user_ratings_count.loc[user_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.user_id.isin(active_users)]\n",
    "    \n",
    "    ratings = ratings.drop_duplicates()\n",
    "    ratings = ratings.fillna(0)\n",
    "    \n",
    "    ratings.to_pickle(\"data/ratings_feature_set.pkl\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split Reviews Data into Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_test_split(years = 1):\n",
    "    ratings = pickle.load(open(\"data/ratings_feature_set.pkl\", \"rb\"))\n",
    "    \n",
    "    # subsetting ratings for specified number of years\n",
    "    ratings['year'] = ratings['date'].apply(lambda x : x.split('-')[0])\n",
    "    years_list = set(ratings['year'])\n",
    "    years_list = sorted(years_list, reverse = True)[0:years]\n",
    "    ratings = ratings[ratings.year.isin(years_list)]\n",
    "    ratings.drop(['year'], axis = 1, inplace = True)\n",
    "    \n",
    "    # subsetting active businesses based on >=5 ratings\n",
    "    business_ratings_count = ratings['business_id'].value_counts()\n",
    "    active_business = business_ratings_count.loc[business_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.business_id.isin(active_business)]\n",
    "    \n",
    "    # subsetting active users based on >=5 ratings\n",
    "    user_ratings_count = ratings['user_id'].value_counts()\n",
    "    active_users = user_ratings_count.loc[user_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.user_id.isin(active_users)]\n",
    "    \n",
    "    # hold out latest review for each user by review date\n",
    "    holdout_set = ratings.sort_values(by = ['date'], ascending = False).groupby('user_id').first().reset_index()\n",
    "    holdout_reviews = holdout_set['review_id'].values.tolist()\n",
    "    \n",
    "    # construct train set from all reviews and test set from holdout review\n",
    "    ratings_train = ratings[~ratings.review_id.isin(holdout_reviews)]\n",
    "    ratings_test = holdout_set\n",
    "    \n",
    "    # select two ratings per user for validation set\n",
    "    random_two = lambda x: x.loc[np.random.choice(x.index, 2, False), :]\n",
    "    ratings_validation = ratings_train.groupby('user_id', as_index = False).apply(random_two)\n",
    "    ratings_validation.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    # excluding validation set data from training set\n",
    "    validation_reviews = ratings_validation['review_id'].values.tolist()\n",
    "    ratings_train = ratings_train[~ratings_train.review_id.isin(validation_reviews)]\n",
    "    \n",
    "    # persisting pickle object for specified years\n",
    "    ratings_train.to_pickle(\"data/ratings_train_\"+str(years)+\"_years.pkl\")\n",
    "    ratings_validation.to_pickle(\"data/ratings_validation_\"+str(years)+\"_years.pkl\")\n",
    "    ratings_test.to_pickle(\"data/ratings_test_\"+str(years)+\"_years.pkl\")\n",
    "    \n",
    "    return ratings_train, ratings_validation, ratings_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Identify Possible Recommendation Options for Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_recommendation_options(ratings):\n",
    "    all_users = list(set(ratings.user_id))\n",
    "    all_business = list(set(ratings.business_id))\n",
    "    all_user_business = list(itertools.product(all_users, all_business))\n",
    "    \n",
    "    ratings_reviewed = list()\n",
    "    ratings.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    for i in range(len(ratings)):\n",
    "        ratings_reviewed.append((ratings.user_id.iloc[i], ratings.business_id.iloc[i]))\n",
    "    \n",
    "    ratings_recommend = set(all_user_business) - set(ratings_reviewed)\n",
    "    ratings_recommend = pd.DataFrame(ratings_recommend, columns = ['user_id', 'business_id'])\n",
    "    \n",
    "    ratings_recommend.to_pickle(\"data/ratings_recommendation_list_full.pkl\")\n",
    "    \n",
    "    return ratings_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_recommendations(ratings_train, ratings_recommend):\n",
    "    # maintaining ratio when subsetting\n",
    "    n_users = 4000\n",
    "    n_businesses = 500\n",
    "    \n",
    "    all_users = list(ratings_train.groupby(['user_id']).groups.keys())\n",
    "    all_businesses = list(ratings_train.groupby(['business_id']).groups.keys())\n",
    "    \n",
    "    # randomly selecting n_users and n_businesses\n",
    "    sample_users = random.choices(all_users, k = n_users)\n",
    "    sample_businesses = random.choices(all_businesses, k = n_businesses)\n",
    "    \n",
    "    # generating smaller list for recommendation\n",
    "    ratings_recommend = ratings_recommend[ratings_recommend.user_id.isin(sample_users)]\n",
    "    ratings_recommend = ratings_recommend[ratings_recommend.business_id.isin(sample_businesses)]\n",
    "    \n",
    "    ratings_recommend.to_pickle(\"data/ratings_recommendation_list.pkl\")\n",
    "    \n",
    "    return ratings_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calls\n",
    "# ratings, business, checkin, user, tips = get_yelp_data()\n",
    "\n",
    "# user = add_user_features(user, ratings, tips)\n",
    "# business = add_item_features(business, checkin)\n",
    "# ratings = add_features_to_ratings(ratings, user, business)\n",
    "# ratings_train, ratings_validation, ratings_test = train_validation_test_split(5)\n",
    "\n",
    "# ratings_recommend = user_recommendation_options(ratings_train)\n",
    "# ratings_recommend_subset = subset_recommendations(ratings_train, ratings_recommend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 512.96878,
   "position": {
    "height": "213.646px",
    "left": "1059.8px",
    "right": "20px",
    "top": "37.7882px",
    "width": "447.691px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
