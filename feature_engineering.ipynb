{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import import_ipynb\n",
    "import data_acquisition\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yelp_data():\n",
    "    # invoking data import functions\n",
    "    ratings = data_acquisition.get_ratings_data()\n",
    "    business = data_acquisition.get_business_data()\n",
    "    checkin = data_acquisition.get_checkin_data()\n",
    "    user = data_acquisition.get_user_data()\n",
    "    tips = data_acquisition.get_tips_data()\n",
    "    \n",
    "    return ratings, business, checkin, user, tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_features(user, ratings, tips):\n",
    "    active_users = pickle.load(open(\"data/active_users_list.pkl\", \"rb\"))\n",
    "    active_users = active_users[0].values.tolist()\n",
    "    \n",
    "    # subsetting for active users\n",
    "    user = user[user.user_id.isin(active_users)]\n",
    "    \n",
    "    # for each user, date of last review and total tips provided\n",
    "    last_user_review = ratings.groupby(['user_id'], sort = False)['date'].max().reset_index()\n",
    "    user_tips_count = tips.groupby(['user_id'], sort = False)['compliment_count'].sum().reset_index()\n",
    "\n",
    "    user = user.replace('',np.nan)\n",
    "\n",
    "    # create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()    \n",
    "\n",
    "    #1. normalizing review attributes    \n",
    "    review_norm_mdl = min_max_scaler.fit(user[['review_count']])\n",
    "    user['review_count_norm'] = pd.DataFrame(review_norm_mdl.transform(user[['review_count']])) \n",
    "\n",
    "    #2. compliments per review count index\n",
    "    for col in user.columns[7:17] :\n",
    "        user[col] = user[col]/user['review_count']\n",
    "\n",
    "    #3. total friends for each user normalized\n",
    "    user['friends'] = user['friends'].apply(lambda x : len(x.split(','))) \n",
    "    friends_norm_mdl = min_max_scaler.fit(user[['friends']])\n",
    "    user['friends_norm'] = pd.DataFrame(friends_norm_mdl.transform(user[['friends']])) \n",
    "\n",
    "    #4. total elite years for each user\n",
    "    def elite_count(x):\n",
    "        y = str(x).split(',')\n",
    "        if y[0] == 'nan':\n",
    "            cnt = 0\n",
    "        else:\n",
    "            cnt = len(y)  \n",
    "        return cnt, y\n",
    "\n",
    "    user['elite_intm'] = user['elite'].apply(lambda x : elite_count(x))\n",
    "    user['elite_count'] = [x[0] for x in user['elite_intm']]\n",
    "    user['elite_year'] = [x[1] for x in user['elite_intm']]\n",
    "\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    elite = pd.DataFrame(mlb.fit_transform(user.pop('elite_year')),\n",
    "                         columns = 'elite_' + mlb.classes_, index = user.index)\n",
    "    user = pd.concat([user, elite], axis = 1)\n",
    "    user.drop(['elite_nan'], axis = 1, inplace = True)\n",
    "\n",
    "    #5. yelping since number of days\n",
    "    user['yelping_since'] = (pd.to_datetime(user['yelping_since'])).dt.normalize()\n",
    "    user = user.merge(last_user_review, on = 'user_id', how = 'left')\n",
    "    user['date'] = pd.to_datetime(user['date'], errors = 'ignore', format = '%Y-%m-%d %H:%M:%S')\n",
    "    user['user_lifetime'] = (user['date'] - user['yelping_since']).apply(lambda x: x.days)\n",
    "\n",
    "    #6. tip count normalized for each user\n",
    "    user = user.merge(user_tips_count, on = 'user_id', how = 'left')\n",
    "    user['compliment_count'] = user['compliment_count']/user['review_count']\n",
    "\n",
    "    #7. total fans of each user normalized\n",
    "    fans_norm_mdl = min_max_scaler.fit(user[['fans']])\n",
    "    user['fans_norm'] = pd.DataFrame(fans_norm_mdl.transform(user[['fans']])) \n",
    "\n",
    "    # removing user features not needed\n",
    "    user.drop(['friends', 'fans' , 'yelping_since', 'elite', 'elite_intm', 'date'], axis = 1, inplace = True)\n",
    "    \n",
    "    user.to_pickle(\"data/user_feature_set.pkl\")\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_item_features(business, checkin):\n",
    "    all_categories = []\n",
    "    \n",
    "    # sampling for Las Vegas businesses that are open\n",
    "    business = business[business['is_open'] == 1]\n",
    "    business = business[business['city'] == 'Las Vegas']\n",
    "    \n",
    "    # creating a list for hours of business each day\n",
    "    business['hours'] = business['hours'].apply(lambda x: ' '.join(' '.join(str(x).split(', ')).split(': ')).split())\n",
    "    business.reset_index(inplace = True, drop = True)\n",
    "\n",
    "    for i in tqdm(range(len(business))):\n",
    "        # maintain list of all business categories\n",
    "        all_categories.extend(business.loc[i, 'categories'])\n",
    "\n",
    "        if business.loc[i, 'hours'] == ['None'] or []:\n",
    "            business.loc[i, 'total_hours'] = 0\n",
    "        else:\n",
    "            open_hours = business.loc[i, 'hours'][1::2]\n",
    "            open_hours[-1] = open_hours[-1][:-1]\n",
    "            open_hours = [x[1:len(x)-1].split('-') for x in open_hours]\n",
    "            total_hours = 0\n",
    "            \n",
    "            # computing total hours open per week for each business\n",
    "            for j in range(len(open_hours)):\n",
    "                delta = datetime.strptime(open_hours[j][1], '%H:%M') - datetime.strptime(open_hours[j][0], '%H:%M')\n",
    "                if delta <= timedelta(days = -1, hours = 23):\n",
    "                    delta = delta - timedelta(days=-1)\n",
    "\n",
    "                delta = delta.seconds//3600\n",
    "                total_hours = total_hours + delta\n",
    "            business.loc[i, 'total_hours'] = total_hours\n",
    "            \n",
    "    # subset for 25 most common business categories by count\n",
    "    top25_categories = Counter(all_categories).most_common(25)\n",
    "    category_name = [category for category, count in top25_categories]\n",
    "\n",
    "    business['str_categories'] = business['categories'].apply(lambda x : str(x))\n",
    "\n",
    "    # one-hot encoding to indicate presence of top 25 category for each business\n",
    "    for category in tqdm(category_name):\n",
    "        category_presence = [category_list for category_list in business['categories'] if category in category_list]\n",
    "        category_features = pd.DataFrame(0, index = range(0, len(category_presence)), columns = [category,'presence'])\n",
    "        for i in range(len(category_presence)):\n",
    "            category_features.loc[i, category] = str(category_presence[i])\n",
    "            category_features.loc[i, 'presence'] = 1\n",
    "\n",
    "        category_features = category_features.rename(columns={category: \"str_categories\"})\n",
    "        category_features['str_categories'] = category_features['str_categories'].apply(lambda x : str(x))    \n",
    "        category_features = category_features.drop_duplicates()\n",
    "\n",
    "        business = business.merge(category_features, how = \"left\", on = \"str_categories\")\n",
    "        business = business.rename(columns={\"presence\": category})\n",
    "    \n",
    "    business.drop(['city', 'categories', 'hours', 'str_categories', 'is_open'], axis = 1, inplace = True)\n",
    "    \n",
    "    # finding first, last and total checkins for each business\n",
    "    checkin['total_checkins'] = checkin['date'].apply(lambda x: len(str(x).split(', ')))\n",
    "    checkin['last_checkin'] = checkin['date'].apply(lambda x: max(str(x).split(', ')))\n",
    "    checkin['first_checkin'] = checkin['date'].apply(lambda x: min(str(x).split(', ')))\n",
    "\n",
    "    last_checkin = pd.to_datetime(checkin['last_checkin'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    first_checkin = pd.to_datetime(checkin['first_checkin'], format = '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    # computing age of business in terms of first and last checkin\n",
    "    checkin['age_of_business'] = (last_checkin - first_checkin).apply(lambda x: x.days)\n",
    "    checkin.drop(['date', 'first_checkin', 'last_checkin'], axis = 1, inplace = True)\n",
    "\n",
    "    business = business.merge(checkin, how = 'left', on = 'business_id')\n",
    "    \n",
    "    business.to_pickle(\"data/business_feature_set.pkl\")\n",
    "    return business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features_to_ratings(ratings, user, business):\n",
    "    # imputing user and business attributes to ratings\n",
    "    ratings = ratings.merge(user, on = 'user_id')\n",
    "    ratings = ratings.merge(business, on = 'business_id')\n",
    "    \n",
    "    # subsetting active businesses based on >=5 ratings\n",
    "    business_ratings_count = ratings['business_id'].value_counts()\n",
    "    active_business = business_ratings_count.loc[business_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.business_id.isin(active_business)]\n",
    "    \n",
    "    # subsetting active users based on >=5 ratings\n",
    "    user_ratings_count = ratings['user_id'].value_counts()\n",
    "    active_users = user_ratings_count.loc[user_ratings_count >= 5].index.tolist()\n",
    "    ratings = ratings[ratings.user_id.isin(active_users)]\n",
    "    ratings = ratings.fillna(0)\n",
    "    \n",
    "    ratings.to_pickle(\"data/ratings_feature_set.pkl\")\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(size = 1):\n",
    "    ratings = pickle.load(open(\"data/ratings_feature_set.pkl\", \"rb\"))\n",
    "\n",
    "    users_list = ratings['user_id'].value_counts()\n",
    "    size = int(size * len(users_list))\n",
    "    \n",
    "    # finding a subset of total users randomly\n",
    "    users = random.choices(users_list.index.tolist(), k = size)\n",
    "    ratings = ratings[ratings.user_id.isin(users)]\n",
    "    \n",
    "    # hold out latest review for each user by review date\n",
    "    holdout_set = ratings.sort_values(by = ['date'], ascending = False).groupby('user_id').first().reset_index()\n",
    "    holdout_reviews = holdout_set['review_id'].values.tolist()\n",
    "    \n",
    "    # construct train set from all reviews and test set from holdout review\n",
    "    ratings_train = ratings[~ratings.review_id.isin(holdout_reviews)]\n",
    "    ratings_test = holdout_set\n",
    "\n",
    "    return ratings_train, ratings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calls\n",
    "# ratings, business, checkin, user, tips = get_yelp_data()\n",
    "\n",
    "# user = add_user_features(user, ratings, tips)\n",
    "# business = add_item_features(business, checkin)\n",
    "# ratings = add_features_to_ratings(ratings, user, business)\n",
    "# ratings_train, ratings_test = train_test_split(ratings, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 513,
   "position": {
    "height": "535.208px",
    "left": "806.993px",
    "right": "20px",
    "top": "67.9861px",
    "width": "536.997px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
