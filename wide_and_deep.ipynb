{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from feature_engineering.ipynb\n",
      "importing Jupyter notebook from data_acquisition.ipynb\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import import_ipynb\n",
    "import feature_engineering\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\", category = FutureWarning)\n",
    "    import tensorflow as tf\n",
    "    \n",
    "import tensorflow.python.util.deprecation as deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6685900/6685900 [00:47<00:00, 139737.89it/s]\n",
      "100%|██████████| 192609/192609 [00:03<00:00, 62395.71it/s]\n",
      "100%|██████████| 161950/161950 [00:01<00:00, 127828.20it/s]\n",
      "100%|██████████| 1637138/1637138 [00:20<00:00, 78707.92it/s]\n",
      "100%|██████████| 1223094/1223094 [00:04<00:00, 266029.38it/s]\n"
     ]
    }
   ],
   "source": [
    "ratings, business, checkin, user, tips = feature_engineering.get_yelp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23793/23793 [00:12<00:00, 1929.77it/s]\n",
      "100%|██████████| 25/25 [00:36<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "user = feature_engineering.add_user_features(user, ratings, tips)\n",
    "business = feature_engineering.add_item_features(business, checkin)\n",
    "ratings = feature_engineering.add_features_to_ratings(ratings, user, business)\n",
    "ratings_train, ratings_test = feature_engineering.train_test_split(ratings, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide_and_deep_columns(column_list):\n",
    "    # build categorical columns\n",
    "    \n",
    "    # categorical columns for elite status across years\n",
    "#     for column in column_list[21:34]:\n",
    "#         column = tf.contrib.layers.sparse_column_with_keys(column_name = column, keys = [0, 1])\n",
    "     \n",
    "    # categorical columns for presence of business category\n",
    "    restaurants = tf.contrib.layers.sparse_column_with_keys(column_name = \"Restaurants\", keys = ['0', '1'])\n",
    "    food = tf.contrib.layers.sparse_column_with_keys(column_name = \"Food\", keys = ['0', '1'])\n",
    "\n",
    "    # build continuous columns\n",
    "    #rating = tf.contrib.layers.real_valued_column(\"rating\")\n",
    "    review_count_user = tf.contrib.layers.real_valued_column(\"review_count_x\")\n",
    "    review_count_business = tf.contrib.layers.real_valued_column(\"review_count_y\")\n",
    "    average_stars_user = tf.contrib.layers.real_valued_column(\"average_stars\")\n",
    "    average_stars_business = tf.contrib.layers.real_valued_column(\"stars\")\n",
    "    \n",
    "    # continuous columns for various compliment scores\n",
    "#     for column in column_list[7:18]:\n",
    "#         column = tf.contrib.layers.real_valued_column(column)\n",
    "    \n",
    "    fans = tf.contrib.layers.real_valued_column(\"fans_norm\")\n",
    "    friends = tf.contrib.layers.real_valued_column(\"friends_norm\")\n",
    "    compliments = tf.contrib.layers.real_valued_column(\"compliment_count\")\n",
    "    \n",
    "    elite_count = tf.contrib.layers.real_valued_column(\"elite_count\")\n",
    "    user_lifetime = tf.contrib.layers.real_valued_column(\"user_lifetime\")\n",
    "    compliments = tf.contrib.layers.real_valued_column(\"compliment_count\")\n",
    "    \n",
    "    total_hours = tf.contrib.layers.real_valued_column(\"total_hours\")\n",
    "    total_checkins = tf.contrib.layers.real_valued_column(\"total_checkins\")\n",
    "    age_of_business = tf.contrib.layers.real_valued_column(\"age_of_business\")\n",
    "    \n",
    "    # build wide columns\n",
    "    wide_columns = []\n",
    "    \n",
    "    # build deep columns\n",
    "    deep_columns = [\n",
    "        review_count_user, \n",
    "        review_count_business, \n",
    "        average_stars_user, \n",
    "        average_stars_business, \n",
    "        fans, \n",
    "        friends, \n",
    "        compliments, \n",
    "        elite_count, \n",
    "        user_lifetime,\n",
    "        total_hours, \n",
    "        total_checkins, \n",
    "        age_of_business\n",
    "    ]\n",
    "    print(review_count_user)\n",
    "    \n",
    "    return wide_columns, deep_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train = ratings_train.fillna(0)\n",
    "ratings_test = ratings_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a949e6eb8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'model/wide_and_deep'}\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"model/wide_and_deep\"\n",
    "\n",
    "wide_deep_model = tf.contrib.learn.DNNLinearCombinedRegressor(\n",
    "    model_dir = model_dir,\n",
    "    linear_feature_columns = wide_and_deep_columns(ratings.columns)[0],\n",
    "    dnn_feature_columns = wide_and_deep_columns(ratings.columns)[1], dnn_hidden_units = [100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(df):\n",
    "    continuous_columns = ['review_count_x', 'review_count_y', 'average_stars', 'stars', \n",
    "                      'fans_norm', 'friends_norm', 'compliment_count', 'elite_count', \n",
    "                      'user_lifetime', 'total_hours', 'total_checkins', 'age_of_business']\n",
    "    \n",
    "    categorical_columns = ['Restaurants', 'Shopping', 'Home Services', 'Health & Medical', \n",
    "                       'Food', 'Beauty & Spas', 'Local Services', 'Automotive', 'Nightlife',\n",
    "                       'Event Planning & Services', 'Professional Services', 'Real Estate', \n",
    "                       'Active Life', 'Fashion','Arts & Entertainment', 'Doctors', 'Bars', \n",
    "                       'Hotels & Travel', 'Hair Salons', 'Fast Food', 'Financial Services', \n",
    "                       'Auto Repair', 'Home & Garden', 'American (Traditional)', 'Coffee & Tea']\n",
    "\n",
    "    continuous_cols = {k: tf.constant(df[k].values) for k in continuous_columns}\n",
    "    categorical_cols = {k: tf.SparseTensor(\n",
    "        indices = [[i, 0] for i in range(df[k].size)],\n",
    "        values = df[k].values,\n",
    "        dense_shape = [df[k].size, 1]) for k in categorical_columns}\n",
    "\n",
    "    feature_cols = dict(list(continuous_cols.items()) + list(categorical_cols.items()))\n",
    "    label = tf.constant(df['rating'].values)\n",
    "\n",
    "    return feature_cols, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(ratings_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "    return input_fn(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-84ed7f9ec794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, input_fn, steps, batch_size, monitors, max_steps)\u001b[0m\n\u001b[1;32m    522\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasic_session_run_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks)\u001b[0m\n\u001b[1;32m   1036\u001b[0m       \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_random_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0mglobal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m       \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m       \u001b[0mtraining_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_create_global_step_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-603a8175fefd>\u001b[0m in \u001b[0;36mtrain_input_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-9a6ddad48be6>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         dense_shape = [df[k].size, 1]) for k in categorical_columns}\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-116-9a6ddad48be6>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         dense_shape = [df[k].size, 1]) for k in categorical_columns}\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfeature_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuous_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, indices, values, dense_shape)\u001b[0m\n\u001b[1;32m    126\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SparseTensor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         indices = ops.convert_to_tensor(\n\u001b[0;32m--> 128\u001b[0;31m             indices, name=\"indices\", dtype=dtypes.int64)\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;31m# TODO(touts): Consider adding mutable_values() when 'values'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# is a VariableOp and updating users of SparseTensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                          as_ref=False):\n\u001b[1;32m    304\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m   \"\"\"\n\u001b[1;32m    245\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 246\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    282\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m    283\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    285\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    464\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    363\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mfn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FilterNotTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m   \u001b[0mmismatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmismatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    363\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0mfn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_FilterNotTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m   \u001b[0mmismatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmismatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_FilterInt\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   return None if isinstance(\n\u001b[1;32m    287\u001b[0m       v, (compat.integral_types, tensor_shape.Dimension)) else _NotNone(v)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   return None if isinstance(\n\u001b[1;32m    287\u001b[0m       v, (compat.integral_types, tensor_shape.Dimension)) else _NotNone(v)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_FilterInt\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   return None if isinstance(\n\u001b[1;32m    287\u001b[0m       v, (compat.integral_types, tensor_shape.Dimension)) else _NotNone(v)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m   return None if isinstance(\n\u001b[1;32m    287\u001b[0m       v, (compat.integral_types, tensor_shape.Dimension)) else _NotNone(v)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_FilterInt\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_FirstNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_FilterInt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m   return None if isinstance(\n\u001b[0;32m--> 287\u001b[0;31m       v, (compat.integral_types, tensor_shape.Dimension)) else _NotNone(v)\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_register\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m__instancecheck__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;34m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_abc_instancecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=200)\n",
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print (\"%s: %s\" % (key, results[key]))\n",
    "predictions = m.predict(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols, label = input_fn(ratings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>review_count_x</th>\n",
       "      <th>average_stars_x</th>\n",
       "      <th>compliment_hot_x</th>\n",
       "      <th>compliment_more_x</th>\n",
       "      <th>compliment_profile_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Hotels &amp; Travel_y</th>\n",
       "      <th>Hair Salons_y</th>\n",
       "      <th>Fast Food_y</th>\n",
       "      <th>Financial Services_y</th>\n",
       "      <th>Auto Repair_y</th>\n",
       "      <th>Home &amp; Garden_y</th>\n",
       "      <th>American (Traditional)_y</th>\n",
       "      <th>Coffee &amp; Tea_y</th>\n",
       "      <th>total_checkins_y</th>\n",
       "      <th>age_of_business_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1sbwvVQXV2734tPgoKj4Q</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-05-07 04:34:36</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oy8f3bxyl7zZJFDQ5edtIA</td>\n",
       "      <td>hG7b0MtEbXx5QzbzE6C_VA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-03-27 14:17:13</td>\n",
       "      <td>10</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8F9500ycq3mvpjf0glbFFg</td>\n",
       "      <td>tH0uKD-vNwMoEc3Xk3Cbdg</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-08-17 21:58:24</td>\n",
       "      <td>1184</td>\n",
       "      <td>3.87</td>\n",
       "      <td>0.331926</td>\n",
       "      <td>0.022804</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qH-fr3sCKO0WoryJy44SGQ</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-07-18 11:40:36</td>\n",
       "      <td>485</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.177320</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SnDqhw1IsB34BW1J1Er4mw</td>\n",
       "      <td>renPzRDqMZpMaHiCD_e1_A</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-04-06 14:45:57</td>\n",
       "      <td>485</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.177320</td>\n",
       "      <td>0.016495</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_2_WR2PZHWt_N5IhkjFWbw</td>\n",
       "      <td>QJI9OSEn6ujRCtrX06vs1w</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2011-03-14 00:23:12</td>\n",
       "      <td>1982</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0.645812</td>\n",
       "      <td>0.049445</td>\n",
       "      <td>0.078708</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jxjvu8zMuIIItx7r49EE4A</td>\n",
       "      <td>m-BZLIIh5PCAKnzH0qj_0Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2015-02-22 02:52:26</td>\n",
       "      <td>734</td>\n",
       "      <td>3.63</td>\n",
       "      <td>0.183924</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.010899</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>h_-p8Fs8Kf9dGKFnySVxpA</td>\n",
       "      <td>Fv0e9RIV9jw5TX3ctA1WbA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-07-08 22:12:41</td>\n",
       "      <td>858</td>\n",
       "      <td>3.81</td>\n",
       "      <td>7.386946</td>\n",
       "      <td>1.679487</td>\n",
       "      <td>2.716783</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tRxXnnmVNeriXw6JgfeqhA</td>\n",
       "      <td>k4M43lXJuQMpQW65DTqzIQ</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012-02-09 03:44:59</td>\n",
       "      <td>463</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.522678</td>\n",
       "      <td>0.077754</td>\n",
       "      <td>0.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8Edv5pKe5lOBoN5UZTUI1w</td>\n",
       "      <td>RBXSJA372ilErzNwz0jXvQ</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-02-09 06:45:18</td>\n",
       "      <td>12</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nSbkHMXY9i0Bmhh2AdhARQ</td>\n",
       "      <td>qz0oAuVWUkjeiIpn8s3k8Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-08-03 16:59:47</td>\n",
       "      <td>27</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c_2w1HHWo6GD6t-HarveEA</td>\n",
       "      <td>q_CAgG4x-1K0jTRUtzJz2Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-07-01 22:58:42</td>\n",
       "      <td>52</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rj-m15Quf1gClT6hUSb3Yg</td>\n",
       "      <td>E9yRSEtayhAKwnje3B4lDA</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-11-18 21:08:18</td>\n",
       "      <td>141</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pm6qydbW58BB0zdWCPlBmg</td>\n",
       "      <td>Skzdl0sWhW88525a1vr59g</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-08 19:27:59</td>\n",
       "      <td>6</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MC1Caz9fFrscmQZNgOQ-tA</td>\n",
       "      <td>uYlzvshOSWCTwNLFBELTug</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-07-27 04:39:58</td>\n",
       "      <td>205</td>\n",
       "      <td>3.64</td>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.004878</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8pbq6UaoO8UoAqvSRbe7Iw</td>\n",
       "      <td>h0Nhnq4ubn51BcbkliKE8g</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013-01-15 17:05:02</td>\n",
       "      <td>63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wJoYyWYLg9n_BbyOwWZMWw</td>\n",
       "      <td>Ur4u9wfVtacMnYGbo29ZpQ</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-03-01 02:46:12</td>\n",
       "      <td>252</td>\n",
       "      <td>4.58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UhFeshADGlKt2_qTS3yzeg</td>\n",
       "      <td>GA40olKHiIPkGzqnH4Mjlg</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-25 05:37:29</td>\n",
       "      <td>213</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EF4bJViyM9uwNmvkab6-pA</td>\n",
       "      <td>GA40olKHiIPkGzqnH4Mjlg</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-02-28 17:24:25</td>\n",
       "      <td>213</td>\n",
       "      <td>2.16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>qHioD749hIUrbYfVwXMsPg</td>\n",
       "      <td>U5e8SydGJmpPJs1_ErAWdw</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-03-07 14:41:19</td>\n",
       "      <td>18</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InNWNl-L-bK6Q6JMHgsGjg</td>\n",
       "      <td>eteU71BreWIONFxtIsCP9Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014-11-27 02:18:00</td>\n",
       "      <td>659</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.144158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RUnIyZz6rxcEwMPVEFtMZA</td>\n",
       "      <td>eteU71BreWIONFxtIsCP9Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-01-23 03:42:01</td>\n",
       "      <td>659</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.144158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6hkYIFGZqOT6imfw4F4KCA</td>\n",
       "      <td>eteU71BreWIONFxtIsCP9Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2010-05-10 03:40:30</td>\n",
       "      <td>659</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.863429</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.144158</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>CbZzqWY0GCUv_jeoZMkTDg</td>\n",
       "      <td>CHuPGiofxPPIxK5cXAS4qg</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2014-11-13 00:27:10</td>\n",
       "      <td>19</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NBuzt5W3t6MOmWUTHqOpmQ</td>\n",
       "      <td>HjyfcIOv1PoLJAoqt-J4GQ</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-10-25 05:20:07</td>\n",
       "      <td>10</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cG9ujooLXVLUn4O12_AdNA</td>\n",
       "      <td>46TNf-5T5EcNFRJPYv_nrw</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015-08-19 16:39:53</td>\n",
       "      <td>219</td>\n",
       "      <td>3.74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>F8m6VnyZEKAGPiT535_4TQ</td>\n",
       "      <td>Hmo9AY2JdZejG5LkLRLU8g</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-10-02 00:24:30</td>\n",
       "      <td>61</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6iICmpwalDCC0kFLbtwTOg</td>\n",
       "      <td>vwLV4TkRMoghs86tB1Ke8Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-07-17 09:02:01</td>\n",
       "      <td>277</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.267148</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.014440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>XBneu3NnL8yyg4GhphFBig</td>\n",
       "      <td>vwLV4TkRMoghs86tB1Ke8Q</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-04-09 23:18:10</td>\n",
       "      <td>277</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.267148</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.014440</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UoUPBrMsp8VGyf3_BBYB7w</td>\n",
       "      <td>56iEnLi8jR--2ranjPSQ4w</td>\n",
       "      <td>ujmEBvifdJM6h6RLv4wQIg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-08-04 10:55:04</td>\n",
       "      <td>63</td>\n",
       "      <td>3.88</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>3178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963503</th>\n",
       "      <td>lJfqRDzdUi5B6B_b9qQ4iw</td>\n",
       "      <td>Ra4dc3WlJ2hoSdOV_WpbLQ</td>\n",
       "      <td>SkVn_O8Bbm0oFd3kq0-sKw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-08-15 23:03:45</td>\n",
       "      <td>12</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963504</th>\n",
       "      <td>Dr0FXJnct6fQ3VxS8Nhm5Q</td>\n",
       "      <td>rLfg_CmTr8YvfHClN-uJ8w</td>\n",
       "      <td>wS3FjGFrz_aTCycEqttSwg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-11 22:10:55</td>\n",
       "      <td>32</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963505</th>\n",
       "      <td>qCDpVse1MGngyz3_NwaJSQ</td>\n",
       "      <td>L-3-xFHXDHhKSMWSJUuDeA</td>\n",
       "      <td>wS3FjGFrz_aTCycEqttSwg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-12-30 03:21:14</td>\n",
       "      <td>12</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963506</th>\n",
       "      <td>EIZA9teAjioMxejnsX5VIw</td>\n",
       "      <td>ydDaIq0eSa5aao9MxZ5yxA</td>\n",
       "      <td>wS3FjGFrz_aTCycEqttSwg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-10-06 05:43:54</td>\n",
       "      <td>9</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963507</th>\n",
       "      <td>QouYmmbgAHkgyvcCbSeu8g</td>\n",
       "      <td>dL37aXvnSnFMbv8G5AOWzg</td>\n",
       "      <td>wS3FjGFrz_aTCycEqttSwg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-01-05 18:07:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963508</th>\n",
       "      <td>dwbmvcwIkZrUfpvOYCNiSw</td>\n",
       "      <td>54t4cgnlks-T7JSbtocJ0Q</td>\n",
       "      <td>wS3FjGFrz_aTCycEqttSwg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-12-21 02:20:30</td>\n",
       "      <td>7</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963513</th>\n",
       "      <td>LkxSpwqic1F97KdGUFMgGA</td>\n",
       "      <td>HcP-4EDx1fcatVBNIe-AaQ</td>\n",
       "      <td>Fn8W08EH93Nts0r8fTugFw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-10-20 23:03:59</td>\n",
       "      <td>9</td>\n",
       "      <td>4.11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963514</th>\n",
       "      <td>rPaUf6iHMu3OUfonFWKLjw</td>\n",
       "      <td>i6DkPAz95X3FtuUCLR_QHQ</td>\n",
       "      <td>Fn8W08EH93Nts0r8fTugFw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018-06-05 18:25:15</td>\n",
       "      <td>18</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963515</th>\n",
       "      <td>uq-0dslEF6Y9wx4kqDdXcw</td>\n",
       "      <td>rJn51gJQtSgw1TAqkB0o6w</td>\n",
       "      <td>Fn8W08EH93Nts0r8fTugFw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2016-08-14 22:20:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963516</th>\n",
       "      <td>rhHjMJxVt7nMcMwaVTnqnQ</td>\n",
       "      <td>7n16eYV5ZTBzzvZqJe9RAQ</td>\n",
       "      <td>Fn8W08EH93Nts0r8fTugFw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-10-20 23:06:38</td>\n",
       "      <td>15</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963517</th>\n",
       "      <td>Wa0SxRqzPpcplBOSMYalVg</td>\n",
       "      <td>njnTp5uQ_qNbmESmPHhcjQ</td>\n",
       "      <td>Fn8W08EH93Nts0r8fTugFw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-10-14 04:46:56</td>\n",
       "      <td>6</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963533</th>\n",
       "      <td>BI4Dcy972N1Q2VxmYOKSnw</td>\n",
       "      <td>vS4RyeqSNHv7gtkFc8uvZA</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-06-28 23:00:23</td>\n",
       "      <td>10</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963534</th>\n",
       "      <td>isBkTk7xp1HA0A0lQUI1Gw</td>\n",
       "      <td>_jhAQXClrJwSApfdFDClog</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-20 17:55:04</td>\n",
       "      <td>6</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963535</th>\n",
       "      <td>wDMbp21qRCCrgnzh2GVhXA</td>\n",
       "      <td>0jl-wp_u8f2wgiTeswr7kg</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018-07-17 21:35:59</td>\n",
       "      <td>21</td>\n",
       "      <td>4.71</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963536</th>\n",
       "      <td>tE87f6BfQRthOz0yfJDzfA</td>\n",
       "      <td>tqUKSXG96edJH9uHxF6egw</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-04-03 23:07:46</td>\n",
       "      <td>10</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963537</th>\n",
       "      <td>thRnMm_gyka0tKxe4DctNw</td>\n",
       "      <td>hmC6USwaC7o21Hkc7DIa_A</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-06-23 16:36:58</td>\n",
       "      <td>8</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963538</th>\n",
       "      <td>ZWKBvxoLdtu_RRQSUcLCgQ</td>\n",
       "      <td>U12s30ma9hq9CtQCpqodDw</td>\n",
       "      <td>QLera8iQeg9g5QGqY3K5tg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-10-31 17:32:18</td>\n",
       "      <td>8</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963544</th>\n",
       "      <td>5ssPKRPSbLeSb3TlJ9KAgw</td>\n",
       "      <td>pF232dpIR2-l6cVCQ7qFSA</td>\n",
       "      <td>HjaSykYIB3o5p3GMVPUasA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-04-08 03:51:23</td>\n",
       "      <td>8</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963545</th>\n",
       "      <td>ZtWQDYzHH79CpR0veJ_1_w</td>\n",
       "      <td>pF232dpIR2-l6cVCQ7qFSA</td>\n",
       "      <td>HjaSykYIB3o5p3GMVPUasA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-04-06 23:27:22</td>\n",
       "      <td>8</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963546</th>\n",
       "      <td>oClkwCZAk-GM_VUnoSfx6Q</td>\n",
       "      <td>pF232dpIR2-l6cVCQ7qFSA</td>\n",
       "      <td>HjaSykYIB3o5p3GMVPUasA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-04-09 18:20:24</td>\n",
       "      <td>8</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963547</th>\n",
       "      <td>ZTetwtNbgbGMCBEhVXzKdA</td>\n",
       "      <td>Y53bvraRuAV7q6-hgzBsDA</td>\n",
       "      <td>HjaSykYIB3o5p3GMVPUasA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-07-01 19:41:19</td>\n",
       "      <td>13</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963548</th>\n",
       "      <td>EhHRmR-4kvXSCvROX-2HWw</td>\n",
       "      <td>dEX7N3idbwcEb18l6Oifug</td>\n",
       "      <td>HjaSykYIB3o5p3GMVPUasA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-03-05 03:48:25</td>\n",
       "      <td>14</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963567</th>\n",
       "      <td>BXWDgDlPSv_JOuh-TiAuVQ</td>\n",
       "      <td>W_0o6LXx2Ge8mg6chcWu8w</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-04-25 05:46:26</td>\n",
       "      <td>11</td>\n",
       "      <td>2.84</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963568</th>\n",
       "      <td>xihdZg7qBrxoXin_738qgg</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-05-20 22:26:51</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963569</th>\n",
       "      <td>8gwUYNmnClkcD7Y778i8Gw</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-11-20 07:03:50</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963570</th>\n",
       "      <td>dUiNAF_gGSoLeKDaaw2Ayg</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-20 18:57:12</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963571</th>\n",
       "      <td>b4CyFHjtIr23PBYi0Uh66A</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-02-04 00:15:28</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963572</th>\n",
       "      <td>XxRXLtyGH3wzC3xSPkzSsQ</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-25 20:17:23</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963573</th>\n",
       "      <td>hrSm0FA5N_N_vJsdvXaWAg</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-01-05 19:31:52</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963574</th>\n",
       "      <td>df8xQS06Ax3URMRYf4n22g</td>\n",
       "      <td>HXtvx13fRHKkSJmH0ZrwQQ</td>\n",
       "      <td>883p8Iq1DGAcrP6GU5XRog</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-12-01 01:36:58</td>\n",
       "      <td>8</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>959309 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     review_id                 user_id  \\\n",
       "0       Q1sbwvVQXV2734tPgoKj4Q  hG7b0MtEbXx5QzbzE6C_VA   \n",
       "1       oy8f3bxyl7zZJFDQ5edtIA  hG7b0MtEbXx5QzbzE6C_VA   \n",
       "2       8F9500ycq3mvpjf0glbFFg  tH0uKD-vNwMoEc3Xk3Cbdg   \n",
       "3       qH-fr3sCKO0WoryJy44SGQ  renPzRDqMZpMaHiCD_e1_A   \n",
       "4       SnDqhw1IsB34BW1J1Er4mw  renPzRDqMZpMaHiCD_e1_A   \n",
       "5       _2_WR2PZHWt_N5IhkjFWbw  QJI9OSEn6ujRCtrX06vs1w   \n",
       "6       jxjvu8zMuIIItx7r49EE4A  m-BZLIIh5PCAKnzH0qj_0Q   \n",
       "7       h_-p8Fs8Kf9dGKFnySVxpA  Fv0e9RIV9jw5TX3ctA1WbA   \n",
       "8       tRxXnnmVNeriXw6JgfeqhA  k4M43lXJuQMpQW65DTqzIQ   \n",
       "9       8Edv5pKe5lOBoN5UZTUI1w  RBXSJA372ilErzNwz0jXvQ   \n",
       "10      nSbkHMXY9i0Bmhh2AdhARQ  qz0oAuVWUkjeiIpn8s3k8Q   \n",
       "11      c_2w1HHWo6GD6t-HarveEA  q_CAgG4x-1K0jTRUtzJz2Q   \n",
       "12      Rj-m15Quf1gClT6hUSb3Yg  E9yRSEtayhAKwnje3B4lDA   \n",
       "13      Pm6qydbW58BB0zdWCPlBmg  Skzdl0sWhW88525a1vr59g   \n",
       "14      MC1Caz9fFrscmQZNgOQ-tA  uYlzvshOSWCTwNLFBELTug   \n",
       "15      8pbq6UaoO8UoAqvSRbe7Iw  h0Nhnq4ubn51BcbkliKE8g   \n",
       "16      wJoYyWYLg9n_BbyOwWZMWw  Ur4u9wfVtacMnYGbo29ZpQ   \n",
       "17      UhFeshADGlKt2_qTS3yzeg  GA40olKHiIPkGzqnH4Mjlg   \n",
       "18      EF4bJViyM9uwNmvkab6-pA  GA40olKHiIPkGzqnH4Mjlg   \n",
       "19      qHioD749hIUrbYfVwXMsPg  U5e8SydGJmpPJs1_ErAWdw   \n",
       "20      InNWNl-L-bK6Q6JMHgsGjg  eteU71BreWIONFxtIsCP9Q   \n",
       "21      RUnIyZz6rxcEwMPVEFtMZA  eteU71BreWIONFxtIsCP9Q   \n",
       "22      6hkYIFGZqOT6imfw4F4KCA  eteU71BreWIONFxtIsCP9Q   \n",
       "23      CbZzqWY0GCUv_jeoZMkTDg  CHuPGiofxPPIxK5cXAS4qg   \n",
       "24      NBuzt5W3t6MOmWUTHqOpmQ  HjyfcIOv1PoLJAoqt-J4GQ   \n",
       "25      cG9ujooLXVLUn4O12_AdNA  46TNf-5T5EcNFRJPYv_nrw   \n",
       "26      F8m6VnyZEKAGPiT535_4TQ  Hmo9AY2JdZejG5LkLRLU8g   \n",
       "27      6iICmpwalDCC0kFLbtwTOg  vwLV4TkRMoghs86tB1Ke8Q   \n",
       "28      XBneu3NnL8yyg4GhphFBig  vwLV4TkRMoghs86tB1Ke8Q   \n",
       "29      UoUPBrMsp8VGyf3_BBYB7w  56iEnLi8jR--2ranjPSQ4w   \n",
       "...                        ...                     ...   \n",
       "963503  lJfqRDzdUi5B6B_b9qQ4iw  Ra4dc3WlJ2hoSdOV_WpbLQ   \n",
       "963504  Dr0FXJnct6fQ3VxS8Nhm5Q  rLfg_CmTr8YvfHClN-uJ8w   \n",
       "963505  qCDpVse1MGngyz3_NwaJSQ  L-3-xFHXDHhKSMWSJUuDeA   \n",
       "963506  EIZA9teAjioMxejnsX5VIw  ydDaIq0eSa5aao9MxZ5yxA   \n",
       "963507  QouYmmbgAHkgyvcCbSeu8g  dL37aXvnSnFMbv8G5AOWzg   \n",
       "963508  dwbmvcwIkZrUfpvOYCNiSw  54t4cgnlks-T7JSbtocJ0Q   \n",
       "963513  LkxSpwqic1F97KdGUFMgGA  HcP-4EDx1fcatVBNIe-AaQ   \n",
       "963514  rPaUf6iHMu3OUfonFWKLjw  i6DkPAz95X3FtuUCLR_QHQ   \n",
       "963515  uq-0dslEF6Y9wx4kqDdXcw  rJn51gJQtSgw1TAqkB0o6w   \n",
       "963516  rhHjMJxVt7nMcMwaVTnqnQ  7n16eYV5ZTBzzvZqJe9RAQ   \n",
       "963517  Wa0SxRqzPpcplBOSMYalVg  njnTp5uQ_qNbmESmPHhcjQ   \n",
       "963533  BI4Dcy972N1Q2VxmYOKSnw  vS4RyeqSNHv7gtkFc8uvZA   \n",
       "963534  isBkTk7xp1HA0A0lQUI1Gw  _jhAQXClrJwSApfdFDClog   \n",
       "963535  wDMbp21qRCCrgnzh2GVhXA  0jl-wp_u8f2wgiTeswr7kg   \n",
       "963536  tE87f6BfQRthOz0yfJDzfA  tqUKSXG96edJH9uHxF6egw   \n",
       "963537  thRnMm_gyka0tKxe4DctNw  hmC6USwaC7o21Hkc7DIa_A   \n",
       "963538  ZWKBvxoLdtu_RRQSUcLCgQ  U12s30ma9hq9CtQCpqodDw   \n",
       "963544  5ssPKRPSbLeSb3TlJ9KAgw  pF232dpIR2-l6cVCQ7qFSA   \n",
       "963545  ZtWQDYzHH79CpR0veJ_1_w  pF232dpIR2-l6cVCQ7qFSA   \n",
       "963546  oClkwCZAk-GM_VUnoSfx6Q  pF232dpIR2-l6cVCQ7qFSA   \n",
       "963547  ZTetwtNbgbGMCBEhVXzKdA  Y53bvraRuAV7q6-hgzBsDA   \n",
       "963548  EhHRmR-4kvXSCvROX-2HWw  dEX7N3idbwcEb18l6Oifug   \n",
       "963567  BXWDgDlPSv_JOuh-TiAuVQ  W_0o6LXx2Ge8mg6chcWu8w   \n",
       "963568  xihdZg7qBrxoXin_738qgg  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963569  8gwUYNmnClkcD7Y778i8Gw  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963570  dUiNAF_gGSoLeKDaaw2Ayg  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963571  b4CyFHjtIr23PBYi0Uh66A  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963572  XxRXLtyGH3wzC3xSPkzSsQ  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963573  hrSm0FA5N_N_vJsdvXaWAg  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "963574  df8xQS06Ax3URMRYf4n22g  HXtvx13fRHKkSJmH0ZrwQQ   \n",
       "\n",
       "                   business_id  rating                 date  review_count_x  \\\n",
       "0       ujmEBvifdJM6h6RLv4wQIg     1.0  2013-05-07 04:34:36              10   \n",
       "1       ujmEBvifdJM6h6RLv4wQIg     1.0  2013-03-27 14:17:13              10   \n",
       "2       ujmEBvifdJM6h6RLv4wQIg     3.0  2012-08-17 21:58:24            1184   \n",
       "3       ujmEBvifdJM6h6RLv4wQIg     5.0  2015-07-18 11:40:36             485   \n",
       "4       ujmEBvifdJM6h6RLv4wQIg     4.0  2015-04-06 14:45:57             485   \n",
       "5       ujmEBvifdJM6h6RLv4wQIg     4.0  2011-03-14 00:23:12            1982   \n",
       "6       ujmEBvifdJM6h6RLv4wQIg     3.0  2015-02-22 02:52:26             734   \n",
       "7       ujmEBvifdJM6h6RLv4wQIg     2.0  2012-07-08 22:12:41             858   \n",
       "8       ujmEBvifdJM6h6RLv4wQIg     4.0  2012-02-09 03:44:59             463   \n",
       "9       ujmEBvifdJM6h6RLv4wQIg     4.0  2017-02-09 06:45:18              12   \n",
       "10      ujmEBvifdJM6h6RLv4wQIg     1.0  2015-08-03 16:59:47              27   \n",
       "11      ujmEBvifdJM6h6RLv4wQIg     1.0  2014-07-01 22:58:42              52   \n",
       "12      ujmEBvifdJM6h6RLv4wQIg     4.0  2013-11-18 21:08:18             141   \n",
       "13      ujmEBvifdJM6h6RLv4wQIg     1.0  2018-05-08 19:27:59               6   \n",
       "14      ujmEBvifdJM6h6RLv4wQIg     1.0  2013-07-27 04:39:58             205   \n",
       "15      ujmEBvifdJM6h6RLv4wQIg     2.0  2013-01-15 17:05:02              63   \n",
       "16      ujmEBvifdJM6h6RLv4wQIg     4.0  2017-03-01 02:46:12             252   \n",
       "17      ujmEBvifdJM6h6RLv4wQIg     1.0  2016-02-25 05:37:29             213   \n",
       "18      ujmEBvifdJM6h6RLv4wQIg     1.0  2016-02-28 17:24:25             213   \n",
       "19      ujmEBvifdJM6h6RLv4wQIg     1.0  2016-03-07 14:41:19              18   \n",
       "20      ujmEBvifdJM6h6RLv4wQIg     2.0  2014-11-27 02:18:00             659   \n",
       "21      ujmEBvifdJM6h6RLv4wQIg     4.0  2013-01-23 03:42:01             659   \n",
       "22      ujmEBvifdJM6h6RLv4wQIg     5.0  2010-05-10 03:40:30             659   \n",
       "23      ujmEBvifdJM6h6RLv4wQIg     4.0  2014-11-13 00:27:10              19   \n",
       "24      ujmEBvifdJM6h6RLv4wQIg     5.0  2017-10-25 05:20:07              10   \n",
       "25      ujmEBvifdJM6h6RLv4wQIg     5.0  2015-08-19 16:39:53             219   \n",
       "26      ujmEBvifdJM6h6RLv4wQIg     1.0  2018-10-02 00:24:30              61   \n",
       "27      ujmEBvifdJM6h6RLv4wQIg     5.0  2016-07-17 09:02:01             277   \n",
       "28      ujmEBvifdJM6h6RLv4wQIg     1.0  2015-04-09 23:18:10             277   \n",
       "29      ujmEBvifdJM6h6RLv4wQIg     1.0  2013-08-04 10:55:04              63   \n",
       "...                        ...     ...                  ...             ...   \n",
       "963503  SkVn_O8Bbm0oFd3kq0-sKw     1.0  2018-08-15 23:03:45              12   \n",
       "963504  wS3FjGFrz_aTCycEqttSwg     5.0  2016-11-11 22:10:55              32   \n",
       "963505  wS3FjGFrz_aTCycEqttSwg     5.0  2016-12-30 03:21:14              12   \n",
       "963506  wS3FjGFrz_aTCycEqttSwg     5.0  2017-10-06 05:43:54               9   \n",
       "963507  wS3FjGFrz_aTCycEqttSwg     5.0  2018-01-05 18:07:00               8   \n",
       "963508  wS3FjGFrz_aTCycEqttSwg     5.0  2017-12-21 02:20:30               7   \n",
       "963513  Fn8W08EH93Nts0r8fTugFw     5.0  2016-10-20 23:03:59               9   \n",
       "963514  Fn8W08EH93Nts0r8fTugFw     3.0  2018-06-05 18:25:15              18   \n",
       "963515  Fn8W08EH93Nts0r8fTugFw     1.0  2016-08-14 22:20:00               9   \n",
       "963516  Fn8W08EH93Nts0r8fTugFw     5.0  2016-10-20 23:06:38              15   \n",
       "963517  Fn8W08EH93Nts0r8fTugFw     1.0  2018-10-14 04:46:56               6   \n",
       "963533  QLera8iQeg9g5QGqY3K5tg     5.0  2017-06-28 23:00:23              10   \n",
       "963534  QLera8iQeg9g5QGqY3K5tg     5.0  2017-07-20 17:55:04               6   \n",
       "963535  QLera8iQeg9g5QGqY3K5tg     5.0  2018-07-17 21:35:59              21   \n",
       "963536  QLera8iQeg9g5QGqY3K5tg     5.0  2017-04-03 23:07:46              10   \n",
       "963537  QLera8iQeg9g5QGqY3K5tg     5.0  2017-06-23 16:36:58               8   \n",
       "963538  QLera8iQeg9g5QGqY3K5tg     5.0  2017-10-31 17:32:18               8   \n",
       "963544  HjaSykYIB3o5p3GMVPUasA     5.0  2016-04-08 03:51:23               8   \n",
       "963545  HjaSykYIB3o5p3GMVPUasA     5.0  2016-04-06 23:27:22               8   \n",
       "963546  HjaSykYIB3o5p3GMVPUasA     5.0  2016-04-09 18:20:24               8   \n",
       "963547  HjaSykYIB3o5p3GMVPUasA     5.0  2017-07-01 19:41:19              13   \n",
       "963548  HjaSykYIB3o5p3GMVPUasA     5.0  2016-03-05 03:48:25              14   \n",
       "963567  883p8Iq1DGAcrP6GU5XRog     1.0  2015-04-25 05:46:26              11   \n",
       "963568  883p8Iq1DGAcrP6GU5XRog     1.0  2018-05-20 22:26:51               8   \n",
       "963569  883p8Iq1DGAcrP6GU5XRog     1.0  2017-11-20 07:03:50               8   \n",
       "963570  883p8Iq1DGAcrP6GU5XRog     1.0  2017-12-20 18:57:12               8   \n",
       "963571  883p8Iq1DGAcrP6GU5XRog     1.0  2018-02-04 00:15:28               8   \n",
       "963572  883p8Iq1DGAcrP6GU5XRog     1.0  2018-01-25 20:17:23               8   \n",
       "963573  883p8Iq1DGAcrP6GU5XRog     1.0  2018-01-05 19:31:52               8   \n",
       "963574  883p8Iq1DGAcrP6GU5XRog     1.0  2017-12-01 01:36:58               8   \n",
       "\n",
       "        average_stars_x  compliment_hot_x  compliment_more_x  \\\n",
       "0                  2.00          0.000000           0.000000   \n",
       "1                  2.00          0.000000           0.000000   \n",
       "2                  3.87          0.331926           0.022804   \n",
       "3                  3.82          0.177320           0.016495   \n",
       "4                  3.82          0.177320           0.016495   \n",
       "5                  3.61          0.645812           0.049445   \n",
       "6                  3.63          0.183924           0.016349   \n",
       "7                  3.81          7.386946           1.679487   \n",
       "8                  3.67          0.522678           0.077754   \n",
       "9                  3.67          0.000000           0.000000   \n",
       "10                 1.94          0.000000           0.000000   \n",
       "11                 2.59          0.000000           0.000000   \n",
       "12                 4.51          0.007092           0.000000   \n",
       "13                 3.29          0.000000           0.000000   \n",
       "14                 3.64          0.073171           0.009756   \n",
       "15                 2.94          0.190476           0.000000   \n",
       "16                 4.58          0.000000           0.003968   \n",
       "17                 2.16          0.000000           0.000000   \n",
       "18                 2.16          0.000000           0.000000   \n",
       "19                 3.00          0.000000           0.000000   \n",
       "20                 3.65          0.863429           0.072838   \n",
       "21                 3.65          0.863429           0.072838   \n",
       "22                 3.65          0.863429           0.072838   \n",
       "23                 2.35          0.000000           0.052632   \n",
       "24                 4.80          0.000000           0.000000   \n",
       "25                 3.74          0.000000           0.004566   \n",
       "26                 4.11          0.032787           0.000000   \n",
       "27                 3.88          0.267148           0.010830   \n",
       "28                 3.88          0.267148           0.010830   \n",
       "29                 3.88          0.015873           0.000000   \n",
       "...                 ...               ...                ...   \n",
       "963503             3.11          0.000000           0.000000   \n",
       "963504             3.69          0.000000           0.000000   \n",
       "963505             3.71          0.083333           0.083333   \n",
       "963506             5.00          0.000000           0.000000   \n",
       "963507             2.50          0.000000           0.000000   \n",
       "963508             4.00          0.000000           0.000000   \n",
       "963513             4.11          0.000000           0.111111   \n",
       "963514             3.89          0.000000           0.000000   \n",
       "963515             2.33          0.000000           0.000000   \n",
       "963516             2.88          0.000000           0.000000   \n",
       "963517             4.43          0.000000           0.000000   \n",
       "963533             3.90          0.000000           0.000000   \n",
       "963534             4.33          0.000000           0.000000   \n",
       "963535             4.71          0.047619           0.000000   \n",
       "963536             4.90          0.000000           0.000000   \n",
       "963537             5.00          0.000000           0.125000   \n",
       "963538             4.63          0.000000           0.000000   \n",
       "963544             4.50          0.000000           0.000000   \n",
       "963545             4.50          0.000000           0.000000   \n",
       "963546             4.50          0.000000           0.000000   \n",
       "963547             4.92          0.000000           0.000000   \n",
       "963548             4.33          0.000000           0.000000   \n",
       "963567             2.84          0.000000           0.000000   \n",
       "963568             1.57          0.000000           0.000000   \n",
       "963569             1.57          0.000000           0.000000   \n",
       "963570             1.57          0.000000           0.000000   \n",
       "963571             1.57          0.000000           0.000000   \n",
       "963572             1.57          0.000000           0.000000   \n",
       "963573             1.57          0.000000           0.000000   \n",
       "963574             1.57          0.000000           0.000000   \n",
       "\n",
       "        compliment_profile_x  ...  Hotels & Travel_y  Hair Salons_y  \\\n",
       "0                   0.000000  ...                NaN            NaN   \n",
       "1                   0.000000  ...                NaN            NaN   \n",
       "2                   0.006757  ...                NaN            NaN   \n",
       "3                   0.028866  ...                NaN            NaN   \n",
       "4                   0.028866  ...                NaN            NaN   \n",
       "5                   0.078708  ...                NaN            NaN   \n",
       "6                   0.010899  ...                NaN            NaN   \n",
       "7                   2.716783  ...                NaN            NaN   \n",
       "8                   0.062635  ...                NaN            NaN   \n",
       "9                   0.000000  ...                NaN            NaN   \n",
       "10                  0.000000  ...                NaN            NaN   \n",
       "11                  0.000000  ...                NaN            NaN   \n",
       "12                  0.000000  ...                NaN            NaN   \n",
       "13                  0.000000  ...                NaN            NaN   \n",
       "14                  0.004878  ...                NaN            NaN   \n",
       "15                  0.000000  ...                NaN            NaN   \n",
       "16                  0.000000  ...                NaN            NaN   \n",
       "17                  0.000000  ...                NaN            NaN   \n",
       "18                  0.000000  ...                NaN            NaN   \n",
       "19                  0.000000  ...                NaN            NaN   \n",
       "20                  0.144158  ...                NaN            NaN   \n",
       "21                  0.144158  ...                NaN            NaN   \n",
       "22                  0.144158  ...                NaN            NaN   \n",
       "23                  0.000000  ...                NaN            NaN   \n",
       "24                  0.000000  ...                NaN            NaN   \n",
       "25                  0.000000  ...                NaN            NaN   \n",
       "26                  0.016393  ...                NaN            NaN   \n",
       "27                  0.014440  ...                NaN            NaN   \n",
       "28                  0.014440  ...                NaN            NaN   \n",
       "29                  0.000000  ...                NaN            NaN   \n",
       "...                      ...  ...                ...            ...   \n",
       "963503              0.000000  ...                NaN            NaN   \n",
       "963504              0.000000  ...                NaN            NaN   \n",
       "963505              0.000000  ...                NaN            NaN   \n",
       "963506              0.000000  ...                NaN            NaN   \n",
       "963507              0.000000  ...                NaN            NaN   \n",
       "963508              0.000000  ...                NaN            NaN   \n",
       "963513              0.000000  ...                NaN            NaN   \n",
       "963514              0.000000  ...                NaN            NaN   \n",
       "963515              0.000000  ...                NaN            NaN   \n",
       "963516              0.000000  ...                NaN            NaN   \n",
       "963517              0.000000  ...                NaN            NaN   \n",
       "963533              0.000000  ...                NaN            NaN   \n",
       "963534              0.000000  ...                NaN            NaN   \n",
       "963535              0.000000  ...                NaN            NaN   \n",
       "963536              0.000000  ...                NaN            NaN   \n",
       "963537              0.000000  ...                NaN            NaN   \n",
       "963538              0.000000  ...                NaN            NaN   \n",
       "963544              0.000000  ...                NaN            NaN   \n",
       "963545              0.000000  ...                NaN            NaN   \n",
       "963546              0.000000  ...                NaN            NaN   \n",
       "963547              0.000000  ...                NaN            NaN   \n",
       "963548              0.000000  ...                NaN            NaN   \n",
       "963567              0.000000  ...                NaN            NaN   \n",
       "963568              0.000000  ...                NaN            NaN   \n",
       "963569              0.000000  ...                NaN            NaN   \n",
       "963570              0.000000  ...                NaN            NaN   \n",
       "963571              0.000000  ...                NaN            NaN   \n",
       "963572              0.000000  ...                NaN            NaN   \n",
       "963573              0.000000  ...                NaN            NaN   \n",
       "963574              0.000000  ...                NaN            NaN   \n",
       "\n",
       "        Fast Food_y  Financial Services_y  Auto Repair_y  Home & Garden_y  \\\n",
       "0               NaN                   NaN            NaN              NaN   \n",
       "1               NaN                   NaN            NaN              NaN   \n",
       "2               NaN                   NaN            NaN              NaN   \n",
       "3               NaN                   NaN            NaN              NaN   \n",
       "4               NaN                   NaN            NaN              NaN   \n",
       "5               NaN                   NaN            NaN              NaN   \n",
       "6               NaN                   NaN            NaN              NaN   \n",
       "7               NaN                   NaN            NaN              NaN   \n",
       "8               NaN                   NaN            NaN              NaN   \n",
       "9               NaN                   NaN            NaN              NaN   \n",
       "10              NaN                   NaN            NaN              NaN   \n",
       "11              NaN                   NaN            NaN              NaN   \n",
       "12              NaN                   NaN            NaN              NaN   \n",
       "13              NaN                   NaN            NaN              NaN   \n",
       "14              NaN                   NaN            NaN              NaN   \n",
       "15              NaN                   NaN            NaN              NaN   \n",
       "16              NaN                   NaN            NaN              NaN   \n",
       "17              NaN                   NaN            NaN              NaN   \n",
       "18              NaN                   NaN            NaN              NaN   \n",
       "19              NaN                   NaN            NaN              NaN   \n",
       "20              NaN                   NaN            NaN              NaN   \n",
       "21              NaN                   NaN            NaN              NaN   \n",
       "22              NaN                   NaN            NaN              NaN   \n",
       "23              NaN                   NaN            NaN              NaN   \n",
       "24              NaN                   NaN            NaN              NaN   \n",
       "25              NaN                   NaN            NaN              NaN   \n",
       "26              NaN                   NaN            NaN              NaN   \n",
       "27              NaN                   NaN            NaN              NaN   \n",
       "28              NaN                   NaN            NaN              NaN   \n",
       "29              NaN                   NaN            NaN              NaN   \n",
       "...             ...                   ...            ...              ...   \n",
       "963503          NaN                   NaN            NaN              NaN   \n",
       "963504          NaN                   NaN            NaN              NaN   \n",
       "963505          NaN                   NaN            NaN              NaN   \n",
       "963506          NaN                   NaN            NaN              NaN   \n",
       "963507          NaN                   NaN            NaN              NaN   \n",
       "963508          NaN                   NaN            NaN              NaN   \n",
       "963513          NaN                   NaN            NaN              NaN   \n",
       "963514          NaN                   NaN            NaN              NaN   \n",
       "963515          NaN                   NaN            NaN              NaN   \n",
       "963516          NaN                   NaN            NaN              NaN   \n",
       "963517          NaN                   NaN            NaN              NaN   \n",
       "963533          NaN                   NaN            NaN              NaN   \n",
       "963534          NaN                   NaN            NaN              NaN   \n",
       "963535          NaN                   NaN            NaN              NaN   \n",
       "963536          NaN                   NaN            NaN              NaN   \n",
       "963537          NaN                   NaN            NaN              NaN   \n",
       "963538          NaN                   NaN            NaN              NaN   \n",
       "963544          NaN                   NaN            NaN              NaN   \n",
       "963545          NaN                   NaN            NaN              NaN   \n",
       "963546          NaN                   NaN            NaN              NaN   \n",
       "963547          NaN                   NaN            NaN              NaN   \n",
       "963548          NaN                   NaN            NaN              NaN   \n",
       "963567          NaN                   NaN            NaN              NaN   \n",
       "963568          NaN                   NaN            NaN              NaN   \n",
       "963569          NaN                   NaN            NaN              NaN   \n",
       "963570          NaN                   NaN            NaN              NaN   \n",
       "963571          NaN                   NaN            NaN              NaN   \n",
       "963572          NaN                   NaN            NaN              NaN   \n",
       "963573          NaN                   NaN            NaN              NaN   \n",
       "963574          NaN                   NaN            NaN              NaN   \n",
       "\n",
       "        American (Traditional)_y  Coffee & Tea_y  total_checkins_y  \\\n",
       "0                            NaN             NaN            1600.0   \n",
       "1                            NaN             NaN            1600.0   \n",
       "2                            NaN             NaN            1600.0   \n",
       "3                            NaN             NaN            1600.0   \n",
       "4                            NaN             NaN            1600.0   \n",
       "5                            NaN             NaN            1600.0   \n",
       "6                            NaN             NaN            1600.0   \n",
       "7                            NaN             NaN            1600.0   \n",
       "8                            NaN             NaN            1600.0   \n",
       "9                            NaN             NaN            1600.0   \n",
       "10                           NaN             NaN            1600.0   \n",
       "11                           NaN             NaN            1600.0   \n",
       "12                           NaN             NaN            1600.0   \n",
       "13                           NaN             NaN            1600.0   \n",
       "14                           NaN             NaN            1600.0   \n",
       "15                           NaN             NaN            1600.0   \n",
       "16                           NaN             NaN            1600.0   \n",
       "17                           NaN             NaN            1600.0   \n",
       "18                           NaN             NaN            1600.0   \n",
       "19                           NaN             NaN            1600.0   \n",
       "20                           NaN             NaN            1600.0   \n",
       "21                           NaN             NaN            1600.0   \n",
       "22                           NaN             NaN            1600.0   \n",
       "23                           NaN             NaN            1600.0   \n",
       "24                           NaN             NaN            1600.0   \n",
       "25                           NaN             NaN            1600.0   \n",
       "26                           NaN             NaN            1600.0   \n",
       "27                           NaN             NaN            1600.0   \n",
       "28                           NaN             NaN            1600.0   \n",
       "29                           NaN             NaN            1600.0   \n",
       "...                          ...             ...               ...   \n",
       "963503                       NaN             NaN               1.0   \n",
       "963504                       NaN             NaN               NaN   \n",
       "963505                       NaN             NaN               NaN   \n",
       "963506                       NaN             NaN               NaN   \n",
       "963507                       NaN             NaN               NaN   \n",
       "963508                       NaN             NaN               NaN   \n",
       "963513                       NaN             NaN               4.0   \n",
       "963514                       NaN             NaN               4.0   \n",
       "963515                       NaN             NaN               4.0   \n",
       "963516                       NaN             NaN               4.0   \n",
       "963517                       NaN             NaN               4.0   \n",
       "963533                       NaN             NaN               NaN   \n",
       "963534                       NaN             NaN               NaN   \n",
       "963535                       NaN             NaN               NaN   \n",
       "963536                       NaN             NaN               NaN   \n",
       "963537                       NaN             NaN               NaN   \n",
       "963538                       NaN             NaN               NaN   \n",
       "963544                       NaN             NaN               4.0   \n",
       "963545                       NaN             NaN               4.0   \n",
       "963546                       NaN             NaN               4.0   \n",
       "963547                       NaN             NaN               4.0   \n",
       "963548                       NaN             NaN               4.0   \n",
       "963567                       NaN             NaN               NaN   \n",
       "963568                       NaN             NaN               NaN   \n",
       "963569                       NaN             NaN               NaN   \n",
       "963570                       NaN             NaN               NaN   \n",
       "963571                       NaN             NaN               NaN   \n",
       "963572                       NaN             NaN               NaN   \n",
       "963573                       NaN             NaN               NaN   \n",
       "963574                       NaN             NaN               NaN   \n",
       "\n",
       "        age_of_business_y  \n",
       "0                  3178.0  \n",
       "1                  3178.0  \n",
       "2                  3178.0  \n",
       "3                  3178.0  \n",
       "4                  3178.0  \n",
       "5                  3178.0  \n",
       "6                  3178.0  \n",
       "7                  3178.0  \n",
       "8                  3178.0  \n",
       "9                  3178.0  \n",
       "10                 3178.0  \n",
       "11                 3178.0  \n",
       "12                 3178.0  \n",
       "13                 3178.0  \n",
       "14                 3178.0  \n",
       "15                 3178.0  \n",
       "16                 3178.0  \n",
       "17                 3178.0  \n",
       "18                 3178.0  \n",
       "19                 3178.0  \n",
       "20                 3178.0  \n",
       "21                 3178.0  \n",
       "22                 3178.0  \n",
       "23                 3178.0  \n",
       "24                 3178.0  \n",
       "25                 3178.0  \n",
       "26                 3178.0  \n",
       "27                 3178.0  \n",
       "28                 3178.0  \n",
       "29                 3178.0  \n",
       "...                   ...  \n",
       "963503                0.0  \n",
       "963504                NaN  \n",
       "963505                NaN  \n",
       "963506                NaN  \n",
       "963507                NaN  \n",
       "963508                NaN  \n",
       "963513             1274.0  \n",
       "963514             1274.0  \n",
       "963515             1274.0  \n",
       "963516             1274.0  \n",
       "963517             1274.0  \n",
       "963533                NaN  \n",
       "963534                NaN  \n",
       "963535                NaN  \n",
       "963536                NaN  \n",
       "963537                NaN  \n",
       "963538                NaN  \n",
       "963544              714.0  \n",
       "963545              714.0  \n",
       "963546              714.0  \n",
       "963547              714.0  \n",
       "963548              714.0  \n",
       "963567                NaN  \n",
       "963568                NaN  \n",
       "963569                NaN  \n",
       "963570                NaN  \n",
       "963571                NaN  \n",
       "963572                NaN  \n",
       "963573                NaN  \n",
       "963574                NaN  \n",
       "\n",
       "[959309 rows x 129 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineering.add_features_to_ratings(ratings, user, business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_SparseColumnKeys(column_name='review_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='user_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='business_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='rating', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='date', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_x', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='average_stars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_hot', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_more', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_profile', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_cute', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_list', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_note', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_plain', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_cool', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_funny', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_writer', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_photos', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='friends_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_count', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2006', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2007', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2008', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2009', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2010', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2011', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2012', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2013', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2014', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2015', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2016', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2017', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2018', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='user_lifetime', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_count', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='fans_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='stars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_y', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='total_hours', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Restaurants', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Shopping', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Home Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Health & Medical', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Beauty & Spas', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Food', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Local Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Automotive', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Event Planning & Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Nightlife', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Professional Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Real Estate', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Active Life', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Arts & Entertainment', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Fashion', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Doctors', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Bars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Hotels & Travel', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Hair Salons', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Fast Food', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Financial Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Auto Repair', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Home & Garden', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='American (Traditional)', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Coffee & Tea', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='total_checkins', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='age_of_business', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='user_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='business_id', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='rating', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='date', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_x', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='average_stars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_hot', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_more', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_profile', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_cute', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_list', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_note', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_plain', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_cool', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_funny', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_writer', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_photos', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='friends_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_count', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2006', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2007', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2008', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2009', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2010', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2011', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2012', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2013', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2014', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2015', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2016', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2017', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='elite_2018', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='user_lifetime', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='compliment_count', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='fans_norm', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='stars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='review_count_y', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='total_hours', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Restaurants', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Shopping', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Home Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Health & Medical', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Beauty & Spas', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Food', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Local Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Automotive', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Event Planning & Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Nightlife', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Professional Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Real Estate', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Active Life', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Arts & Entertainment', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Fashion', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Doctors', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Bars', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Hotels & Travel', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Hair Salons', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Fast Food', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Financial Services', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Auto Repair', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Home & Garden', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='American (Traditional)', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='Coffee & Tea', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='total_checkins', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string),\n",
       " _SparseColumnKeys(column_name='age_of_business', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=(0, 1), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_and_deep_columns(ratings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/wide_and_deep/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model/wide_and_deep/model.ckpt.\n",
      "INFO:tensorflow:loss = 291058.03, step = 1\n",
      "INFO:tensorflow:global_step/sec: 24.6819\n",
      "INFO:tensorflow:loss = 451.11353, step = 101 (4.050 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into model/wide_and_deep/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 214.20366.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNLinearCombinedRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x1a949e63c8>, 'linear_feature_columns': [], 'linear_optimizer': None, 'joint_linear_weights': False, 'dnn_feature_columns': [_RealValuedColumn(column_name='review_count_x', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='review_count_y', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='average_stars', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='stars', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='fans_norm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='friends_norm', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='compliment_count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='elite_count', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='user_lifetime', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='total_hours', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='total_checkins', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), _RealValuedColumn(column_name='age_of_business', dimension=1, default_value=None, dtype=tf.float32, normalizer=None)], 'dnn_optimizer': None, 'dnn_hidden_units': [100, 50], 'dnn_activation_fn': <function relu at 0x1a2b9fec80>, 'dnn_dropout': None, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_partitioner': None, 'fix_global_step_increment_bug': False})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_deep_model.fit(input_fn = train_input_fn, steps = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Starting evaluation at 2019-12-08T21:19:44Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/wide_and_deep/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2019-12-08-21:19:45\n",
      "INFO:tensorflow:Saving dict for global step 200: global_step = 200, loss = 196.96843\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/wide_and_deep/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "results = wide_deep_model.evaluate(input_fn = eval_input_fn, steps = 1)\n",
    "\n",
    "predictions = wide_deep_model.predict(input_fn = eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.2903492,\n",
       " 1.3618993,\n",
       " 6.1883764,\n",
       " 35.32661,\n",
       " -6.6277437,\n",
       " 4.1021943,\n",
       " 13.422633,\n",
       " 6.070941,\n",
       " -0.7448741,\n",
       " 9.0258665,\n",
       " 15.274947,\n",
       " -3.2463772,\n",
       " 6.0869436,\n",
       " 30.128344,\n",
       " 52.394886,\n",
       " 4.7410207,\n",
       " 5.3426695,\n",
       " 4.882965,\n",
       " 15.792027,\n",
       " 8.654857,\n",
       " 8.716699,\n",
       " -2.9073575,\n",
       " 36.275196,\n",
       " 7.3808775,\n",
       " 6.1253996,\n",
       " 17.268648,\n",
       " 2.8330066,\n",
       " 6.977158,\n",
       " 5.115753,\n",
       " 10.039898,\n",
       " 5.5943375,\n",
       " 9.820549,\n",
       " -9.092191,\n",
       " 6.5817785,\n",
       " 27.33782,\n",
       " -1.8554965,\n",
       " 15.585582,\n",
       " 4.1789675,\n",
       " -20.139746,\n",
       " 90.1436,\n",
       " -0.900632,\n",
       " 9.220676,\n",
       " 15.945239,\n",
       " 57.671925,\n",
       " -4.183235,\n",
       " -8.421681,\n",
       " -4.784896,\n",
       " 11.63626,\n",
       " 3.1336925,\n",
       " 9.7518015,\n",
       " 7.715623,\n",
       " 3.7785327,\n",
       " 2.7081168,\n",
       " 5.2513,\n",
       " 13.921277,\n",
       " 12.480388,\n",
       " 8.614917,\n",
       " 17.8439,\n",
       " 0.9932693,\n",
       " 3.2426631,\n",
       " 0.18297087,\n",
       " 7.1383986,\n",
       " 5.827576,\n",
       " 4.966444,\n",
       " 5.760176,\n",
       " 25.848497,\n",
       " 0.34216103,\n",
       " 0.5261029,\n",
       " 2.2954967,\n",
       " 6.155335,\n",
       " 0.2762631,\n",
       " 4.5622797,\n",
       " 1.8304456,\n",
       " 0.017728668,\n",
       " -0.3144304,\n",
       " 8.268209,\n",
       " 22.726976,\n",
       " 18.61616,\n",
       " 12.40285,\n",
       " 10.722749,\n",
       " 14.876422,\n",
       " 9.332862,\n",
       " 8.601043,\n",
       " 7.618396,\n",
       " 9.343854,\n",
       " 12.518809,\n",
       " 27.956911,\n",
       " 15.109466,\n",
       " 21.620401,\n",
       " -6.0730705,\n",
       " 9.703211,\n",
       " 9.09826,\n",
       " -5.1779757,\n",
       " 4.4309645,\n",
       " 12.610858,\n",
       " -27.017454,\n",
       " 12.518939,\n",
       " 2.5146954,\n",
       " -1.081174,\n",
       " 1.0276669,\n",
       " -20.597273,\n",
       " 35.63355,\n",
       " -55.28825,\n",
       " 1.1251172,\n",
       " 4.304428,\n",
       " -11.592429,\n",
       " 31.884142,\n",
       " -2.004029,\n",
       " 8.770015,\n",
       " 6.397303,\n",
       " 5.9696507,\n",
       " 3.753411,\n",
       " 13.534214,\n",
       " -9.078582,\n",
       " 7.1710796,\n",
       " -0.39571396,\n",
       " 7.1075597,\n",
       " 3.7843578,\n",
       " 16.47859,\n",
       " 23.063047,\n",
       " 5.34418,\n",
       " 1.4760693,\n",
       " 11.8806925,\n",
       " -9.887793,\n",
       " 10.860141,\n",
       " 1.7994741,\n",
       " -2.3729503,\n",
       " 11.359223,\n",
       " -0.32120624,\n",
       " 13.682485,\n",
       " -2.7725685,\n",
       " 4.8317556,\n",
       " -4.970976,\n",
       " 19.568308,\n",
       " 3.8849604,\n",
       " 8.203616,\n",
       " -56.661877,\n",
       " 5.207465,\n",
       " 11.093982,\n",
       " -0.1367742,\n",
       " 2.8833196,\n",
       " 3.993912,\n",
       " 0.85957587,\n",
       " 15.590005,\n",
       " 0.89694154,\n",
       " 1.2631062,\n",
       " 10.189388,\n",
       " 13.807307,\n",
       " -9.115616,\n",
       " 7.944231,\n",
       " 0.21160398,\n",
       " -2.286125,\n",
       " 2.1394174,\n",
       " 4.5899544,\n",
       " 3.3020318,\n",
       " 0.19134031,\n",
       " 1.879979,\n",
       " 4.435346,\n",
       " 0.69964397,\n",
       " 6.397626,\n",
       " 23.280592,\n",
       " 0.5633668,\n",
       " -50.797863,\n",
       " -11.361737,\n",
       " -12.305431,\n",
       " -13.001157,\n",
       " 7.0995207,\n",
       " 5.91825,\n",
       " -4.464856,\n",
       " 54.085896,\n",
       " -0.57495415,\n",
       " 22.196539,\n",
       " 4.6674185,\n",
       " 4.1252966,\n",
       " -4.8082323,\n",
       " -1.5361592,\n",
       " 5.101725,\n",
       " 0.7652241,\n",
       " -15.841062,\n",
       " 5.2941694,\n",
       " 4.343858,\n",
       " 6.76093,\n",
       " -0.32583728,\n",
       " -4.6692314,\n",
       " 10.315375,\n",
       " -3.498174,\n",
       " 14.899842,\n",
       " 8.634212,\n",
       " 4.0493402,\n",
       " 34.497356,\n",
       " 10.64793,\n",
       " -0.39586845,\n",
       " 23.24663,\n",
       " 53.8745,\n",
       " 5.8553405,\n",
       " 10.702957,\n",
       " 6.220442,\n",
       " 13.652188,\n",
       " 1.7109135,\n",
       " 4.0801764,\n",
       " 6.2536993,\n",
       " -1.387251,\n",
       " 2.195605,\n",
       " 2.1860197,\n",
       " 4.918195,\n",
       " 3.8574626,\n",
       " -2.637542,\n",
       " -15.1477375,\n",
       " 27.291494,\n",
       " -37.73339,\n",
       " 27.380846,\n",
       " 5.4704657,\n",
       " -2.6795628,\n",
       " 26.343828,\n",
       " 31.85295,\n",
       " 65.82524,\n",
       " 5.330238,\n",
       " 7.8644247,\n",
       " 3.4377258,\n",
       " 8.312152,\n",
       " 24.468737,\n",
       " 8.599429,\n",
       " 5.6388083,\n",
       " 7.0062513,\n",
       " 9.132003,\n",
       " 3.1749344,\n",
       " 52.113575,\n",
       " 21.062168,\n",
       " 2.1942346,\n",
       " -6.0673065,\n",
       " 45.187603,\n",
       " 3.0983567,\n",
       " -0.6139833,\n",
       " 23.478777,\n",
       " 9.319964,\n",
       " 13.683713,\n",
       " 24.087938,\n",
       " 4.8391294,\n",
       " 8.851122,\n",
       " 4.674569,\n",
       " 10.320525,\n",
       " 28.076057,\n",
       " 7.617577,\n",
       " -3.1706626,\n",
       " 2.5318134,\n",
       " 22.662785,\n",
       " 7.9836283,\n",
       " -0.7790443,\n",
       " 13.092317,\n",
       " 3.2865922,\n",
       " -3.8580754,\n",
       " -4.162732,\n",
       " -6.2032137,\n",
       " -1.4180642,\n",
       " 10.881053,\n",
       " 32.910206,\n",
       " -0.74847806,\n",
       " 23.596853,\n",
       " 4.044284,\n",
       " 8.905922,\n",
       " 6.8034916,\n",
       " -2.498418,\n",
       " 1.6123551,\n",
       " 9.399756,\n",
       " 0.75546587,\n",
       " -11.787371,\n",
       " 3.5323684,\n",
       " -3.4300873,\n",
       " -0.48537937,\n",
       " 3.3895028,\n",
       " 10.899276,\n",
       " -0.77557886,\n",
       " 5.871089,\n",
       " 14.801997,\n",
       " 7.117693,\n",
       " 23.333788,\n",
       " -10.854473,\n",
       " 5.5570784,\n",
       " 2.8403957,\n",
       " 14.51388,\n",
       " 1.132821,\n",
       " 4.797949,\n",
       " 9.671055,\n",
       " 0.20366989,\n",
       " -2.7969964,\n",
       " 5.591196,\n",
       " 5.1159725,\n",
       " 44.40337,\n",
       " -4.7301846,\n",
       " 11.478822,\n",
       " 3.7882154,\n",
       " 3.2667797,\n",
       " 0.43977627,\n",
       " 5.0065546,\n",
       " 6.247424,\n",
       " 10.570313,\n",
       " 6.0724916,\n",
       " 22.277172,\n",
       " 16.346626,\n",
       " 0.43507847,\n",
       " -5.086047,\n",
       " 1.2349724,\n",
       " 10.2354765,\n",
       " 4.4234343,\n",
       " 5.0226974,\n",
       " 3.7081697,\n",
       " 7.823901,\n",
       " -7.371236,\n",
       " 5.5710373,\n",
       " 18.244398,\n",
       " 27.823666,\n",
       " 2.6358287,\n",
       " 6.1736593,\n",
       " 13.9641695,\n",
       " -19.38059,\n",
       " -1.5923992,\n",
       " 1.4668349,\n",
       " 20.712297,\n",
       " 4.0370054,\n",
       " -0.87325346,\n",
       " 6.1797943,\n",
       " 8.483477,\n",
       " 12.681224,\n",
       " 2.5308158,\n",
       " 21.954058,\n",
       " 9.1993685,\n",
       " -7.359293,\n",
       " 13.43761,\n",
       " -6.320736,\n",
       " 12.48562,\n",
       " -4.9986806,\n",
       " -3.991052,\n",
       " 5.381239,\n",
       " 17.726248,\n",
       " 8.366778,\n",
       " -7.7724886,\n",
       " -2.802573,\n",
       " 3.1900966,\n",
       " 5.023778,\n",
       " 1.6733582,\n",
       " 4.5281005,\n",
       " -23.459486,\n",
       " -16.927183,\n",
       " 6.912547,\n",
       " 0.734002,\n",
       " 21.991106,\n",
       " -1.259089,\n",
       " 1.0978802,\n",
       " 6.0230255,\n",
       " 12.260425,\n",
       " 18.043993,\n",
       " -10.684094,\n",
       " 3.2748668,\n",
       " 18.240294,\n",
       " 4.1836543,\n",
       " -0.020560402,\n",
       " -3.0032103,\n",
       " 16.117792,\n",
       " -16.86276,\n",
       " -4.115838,\n",
       " 13.551982,\n",
       " -1.2240978,\n",
       " 4.3765388,\n",
       " 18.886995,\n",
       " 4.4398556,\n",
       " 31.854864,\n",
       " 5.7093153,\n",
       " 2.9928157,\n",
       " -4.3662233,\n",
       " 10.742541,\n",
       " 2.5333374,\n",
       " 19.232094,\n",
       " 15.74129,\n",
       " 3.3211412,\n",
       " 10.998207,\n",
       " -0.8296701,\n",
       " 4.3323803,\n",
       " -25.62104,\n",
       " 9.881555,\n",
       " 4.7576685,\n",
       " 36.111725,\n",
       " 8.389335,\n",
       " 9.014539,\n",
       " 10.877949,\n",
       " 4.657031,\n",
       " 23.307093,\n",
       " -5.27448,\n",
       " 5.288699,\n",
       " 7.2805014,\n",
       " -0.8187915,\n",
       " 32.0161,\n",
       " 14.296919,\n",
       " 26.350733,\n",
       " 0.106358625,\n",
       " -27.873014,\n",
       " 0.25907215,\n",
       " -19.799894,\n",
       " -1.0774051,\n",
       " -5.9465303,\n",
       " -1.5953437,\n",
       " 3.8642867,\n",
       " 2.8317134,\n",
       " 8.534442,\n",
       " 2.7379148,\n",
       " 27.35631,\n",
       " 1.6561794,\n",
       " 6.956897,\n",
       " 1.3834256,\n",
       " 5.8828244,\n",
       " 22.403568,\n",
       " -7.485756,\n",
       " 2.518422,\n",
       " -7.8705873,\n",
       " -2.3222601,\n",
       " -5.0291834,\n",
       " 6.1460013,\n",
       " 6.5744963,\n",
       " -0.6546637,\n",
       " -4.7668657,\n",
       " 28.848732,\n",
       " 8.257018,\n",
       " 7.244518,\n",
       " -0.35300174,\n",
       " 4.392291,\n",
       " 10.625026,\n",
       " -17.837437,\n",
       " 4.1557837,\n",
       " 6.591965,\n",
       " -8.18945,\n",
       " 6.3637624,\n",
       " 2.4354198,\n",
       " 4.4794264,\n",
       " 3.2309492,\n",
       " 36.8633,\n",
       " 10.795852,\n",
       " 9.550474,\n",
       " 20.722342,\n",
       " -6.608075,\n",
       " 16.884275,\n",
       " 10.613047,\n",
       " -5.497876,\n",
       " 14.080679,\n",
       " -2.1099026,\n",
       " 8.86114,\n",
       " -1.8483707,\n",
       " 18.043438,\n",
       " 21.719452,\n",
       " -20.095404,\n",
       " 16.030518,\n",
       " 3.8179824,\n",
       " -2.190387,\n",
       " -2.202741,\n",
       " -15.24281,\n",
       " 4.0025864,\n",
       " 28.267626,\n",
       " 8.2118635,\n",
       " 23.77454,\n",
       " -4.896035,\n",
       " -5.0248384,\n",
       " 11.809779,\n",
       " 29.236315,\n",
       " 12.455483,\n",
       " -4.3594637,\n",
       " 1.384982,\n",
       " -8.253919,\n",
       " 8.23302,\n",
       " 1.777006,\n",
       " 4.6339664,\n",
       " 2.7500956,\n",
       " 6.0922356,\n",
       " 9.132596,\n",
       " 4.2918043,\n",
       " 11.713275,\n",
       " -5.568181,\n",
       " 4.6987867,\n",
       " 5.340356,\n",
       " -17.39047,\n",
       " 5.0371876,\n",
       " 0.05500446,\n",
       " 6.248372,\n",
       " 2.8225706,\n",
       " 20.25973,\n",
       " 31.620409,\n",
       " 2.8493207,\n",
       " 3.377027,\n",
       " 3.644015,\n",
       " 29.150248,\n",
       " 6.0972853,\n",
       " -7.20329,\n",
       " 8.054639,\n",
       " 9.855597,\n",
       " 10.090102,\n",
       " 17.836096,\n",
       " 1.4684547,\n",
       " 10.003688,\n",
       " 1.4440736,\n",
       " 5.510582,\n",
       " 65.768265,\n",
       " 1.969356,\n",
       " -3.6218593,\n",
       " 10.775398,\n",
       " -4.8799286,\n",
       " 5.780796,\n",
       " 3.0773952,\n",
       " 7.5045767,\n",
       " -4.9795504,\n",
       " 55.07854,\n",
       " -2.2272956,\n",
       " 0.8089446,\n",
       " 1.0635267,\n",
       " 2.6508934,\n",
       " 13.936873,\n",
       " 5.903412,\n",
       " 24.428883,\n",
       " 10.489507,\n",
       " -30.850866,\n",
       " 30.1888,\n",
       " 4.497143,\n",
       " 14.880996,\n",
       " -1.2039081,\n",
       " 2.8987381,\n",
       " 15.450858,\n",
       " 1.9556168,\n",
       " 9.209193,\n",
       " 8.162014,\n",
       " -9.983832,\n",
       " 5.564711,\n",
       " 31.112837,\n",
       " 6.7366114,\n",
       " 6.3456845,\n",
       " 5.1253157,\n",
       " 7.736358,\n",
       " 11.982965,\n",
       " -5.038925,\n",
       " 22.1706,\n",
       " -7.15611,\n",
       " -2.0768888,\n",
       " 25.18328,\n",
       " 4.328721,\n",
       " 27.98131,\n",
       " 6.787738,\n",
       " -1.6901828,\n",
       " -13.031468,\n",
       " -2.1560776,\n",
       " -5.087041,\n",
       " 3.7649295,\n",
       " 7.60262,\n",
       " -4.2075224,\n",
       " -1.7101833,\n",
       " 3.0919673,\n",
       " 7.594606,\n",
       " 5.01028,\n",
       " -3.463895,\n",
       " 18.375051,\n",
       " -0.43240467,\n",
       " 5.2553587,\n",
       " -10.875089,\n",
       " -3.926244,\n",
       " -2.1634343,\n",
       " 16.381807,\n",
       " 12.651713,\n",
       " 6.882968,\n",
       " 0.77930677,\n",
       " -15.682771,\n",
       " 16.697279,\n",
       " 34.027115,\n",
       " 2.465165,\n",
       " -4.901971,\n",
       " 33.70041,\n",
       " 4.633563,\n",
       " -1.4411594,\n",
       " 5.616326,\n",
       " 2.6762748,\n",
       " -3.0831864,\n",
       " -3.941068,\n",
       " 7.4818273,\n",
       " 20.163202,\n",
       " -7.439079,\n",
       " 1.2008313,\n",
       " 12.721091,\n",
       " 3.1325557,\n",
       " 7.677001,\n",
       " 4.997531,\n",
       " 30.394201,\n",
       " 14.459444,\n",
       " 4.1984754,\n",
       " -4.3357353,\n",
       " -2.4955647,\n",
       " -9.033002,\n",
       " 7.463295,\n",
       " 13.141043,\n",
       " 7.1526823,\n",
       " 4.209895,\n",
       " 2.4218445,\n",
       " 9.260516,\n",
       " 21.115456,\n",
       " 10.353854,\n",
       " -0.098736905,\n",
       " 12.862124,\n",
       " 8.842242,\n",
       " 6.2419252,\n",
       " -1.2587568,\n",
       " -0.0007091956,\n",
       " 8.941665,\n",
       " 3.5099971,\n",
       " 12.329596,\n",
       " 3.6285174,\n",
       " 12.573597,\n",
       " 0.63261974,\n",
       " 3.0247784,\n",
       " 11.30632,\n",
       " 5.225067,\n",
       " 5.1925764,\n",
       " 9.137177,\n",
       " 24.1411,\n",
       " 1.9953374,\n",
       " 3.2087085,\n",
       " 0.38882717,\n",
       " 2.1383111,\n",
       " 8.171618,\n",
       " 4.6470804,\n",
       " -11.417882,\n",
       " -3.7764409,\n",
       " 6.773074,\n",
       " 7.8971434,\n",
       " 8.325455,\n",
       " 22.594225,\n",
       " 12.900998,\n",
       " 3.0914378,\n",
       " 5.9821916,\n",
       " 5.953679,\n",
       " -1.2393562,\n",
       " 3.985741,\n",
       " -2.4776924,\n",
       " 3.2365339,\n",
       " -0.8823081,\n",
       " 2.3916676,\n",
       " 20.882492,\n",
       " 67.78914,\n",
       " 2.3517673,\n",
       " -2.3033993,\n",
       " 6.979436,\n",
       " 14.353019,\n",
       " -13.670412,\n",
       " 56.473072,\n",
       " 6.5077477,\n",
       " -22.226377,\n",
       " 2.2546642,\n",
       " 1.7360295,\n",
       " -0.2767488,\n",
       " -25.548876,\n",
       " -4.0704775,\n",
       " 7.304679,\n",
       " 23.615602,\n",
       " -7.880933,\n",
       " -3.1467812,\n",
       " 22.339582,\n",
       " 0.4080914,\n",
       " -8.630414,\n",
       " 10.444273,\n",
       " 9.538962,\n",
       " -2.3252957,\n",
       " 9.209238,\n",
       " 30.071459,\n",
       " 10.26192,\n",
       " 4.306667,\n",
       " -4.4571486,\n",
       " 4.112938,\n",
       " 13.48914,\n",
       " 11.854547,\n",
       " -4.4639177,\n",
       " 17.300508,\n",
       " 15.221469,\n",
       " -12.261273,\n",
       " -4.06931,\n",
       " 10.34755,\n",
       " 8.481334,\n",
       " 20.083307,\n",
       " 12.894507,\n",
       " 13.038411,\n",
       " 5.3760824,\n",
       " 6.157173,\n",
       " -2.599195,\n",
       " 6.9766874,\n",
       " 6.2649126,\n",
       " 33.955555,\n",
       " 10.145736,\n",
       " -6.90977,\n",
       " -12.442334,\n",
       " 7.153846,\n",
       " -10.358823,\n",
       " 31.578144,\n",
       " -1.8507625,\n",
       " 17.515726,\n",
       " 8.734567,\n",
       " 13.348314,\n",
       " 30.895098,\n",
       " 19.704508,\n",
       " 81.375046,\n",
       " 1.9827718,\n",
       " 34.7285,\n",
       " 6.5096464,\n",
       " 4.588002,\n",
       " 4.333461,\n",
       " 9.945989,\n",
       " 5.4674773,\n",
       " 8.744773,\n",
       " 4.577426,\n",
       " 23.354074,\n",
       " -6.8668394,\n",
       " 7.082629,\n",
       " 0.0017727418,\n",
       " 12.454976,\n",
       " 1.8967658,\n",
       " 2.0661752,\n",
       " -5.0216694,\n",
       " 29.33983,\n",
       " 3.8373716,\n",
       " 21.162212,\n",
       " -9.586156,\n",
       " -5.380494,\n",
       " 5.657031,\n",
       " 0.8203677,\n",
       " -1.8685046,\n",
       " 16.783731,\n",
       " 13.834907,\n",
       " 8.913814,\n",
       " 6.995826,\n",
       " 14.439992,\n",
       " 5.857175,\n",
       " 2.5262744,\n",
       " 6.080859,\n",
       " 2.122862,\n",
       " 15.03197,\n",
       " 7.593978,\n",
       " 7.2613935,\n",
       " 6.454052,\n",
       " 1.8812822,\n",
       " 8.571279,\n",
       " -0.93400156,\n",
       " 30.504286,\n",
       " 34.5053,\n",
       " -8.937757,\n",
       " 3.669556,\n",
       " 12.570669,\n",
       " -4.3715563,\n",
       " -0.8298756,\n",
       " 11.49786,\n",
       " 11.527563,\n",
       " 23.881273,\n",
       " 11.104651,\n",
       " 24.16757,\n",
       " -42.73959,\n",
       " 7.374316,\n",
       " -10.361386,\n",
       " 9.035499,\n",
       " 8.139389,\n",
       " 9.082864,\n",
       " -21.521961,\n",
       " 3.208997,\n",
       " -17.061934,\n",
       " 4.275836,\n",
       " 10.239219,\n",
       " 27.430834,\n",
       " 14.666392,\n",
       " -6.2183237,\n",
       " -6.510978,\n",
       " 17.305422,\n",
       " 3.557049,\n",
       " 2.5626245,\n",
       " -10.6323805,\n",
       " 2.8431518,\n",
       " 23.51867,\n",
       " -0.2695476,\n",
       " 11.191495,\n",
       " 4.2825537,\n",
       " 1.7395743,\n",
       " 3.1820552,\n",
       " 51.128223,\n",
       " 8.767386,\n",
       " -0.80986893,\n",
       " 2.8980448,\n",
       " 4.0963163,\n",
       " 21.611162,\n",
       " 76.017136,\n",
       " 6.792102,\n",
       " 14.067781,\n",
       " 27.527805,\n",
       " 1.6727202,\n",
       " -8.0175295,\n",
       " 10.031773,\n",
       " 7.648548,\n",
       " -5.6035695,\n",
       " 15.42855,\n",
       " 6.769908,\n",
       " 15.753762,\n",
       " 2.2718985,\n",
       " -5.1993723,\n",
       " -0.62943757,\n",
       " 7.4934225,\n",
       " 5.0939364,\n",
       " 14.92596,\n",
       " -1.341201,\n",
       " 2.938769,\n",
       " 13.928554,\n",
       " 12.665059,\n",
       " 9.9488325,\n",
       " 87.833786,\n",
       " -4.069027,\n",
       " 19.05646,\n",
       " 8.74941,\n",
       " 4.7191434,\n",
       " 21.947584,\n",
       " 13.527605,\n",
       " 12.103702,\n",
       " 2.277991,\n",
       " -0.15332378,\n",
       " 5.288865,\n",
       " -24.987047,\n",
       " 4.224962,\n",
       " 19.706648,\n",
       " 6.5343046,\n",
       " 13.924418,\n",
       " 11.264802,\n",
       " 1.2263402,\n",
       " 14.37433,\n",
       " -5.315544,\n",
       " 3.0291927,\n",
       " 22.058136,\n",
       " -14.853009,\n",
       " -4.2543154,\n",
       " 0.16369902,\n",
       " 23.804375,\n",
       " 5.984084,\n",
       " 2.995711,\n",
       " 2.4043214,\n",
       " 31.429766,\n",
       " 5.571983,\n",
       " 46.842274,\n",
       " -12.768567,\n",
       " 0.84785545,\n",
       " 7.4254045,\n",
       " 6.0055914,\n",
       " 7.427413,\n",
       " 4.8723335,\n",
       " 32.774742,\n",
       " -5.516552,\n",
       " 7.400895,\n",
       " 2.1714656,\n",
       " -8.442838,\n",
       " 1.7931088,\n",
       " 3.6117454,\n",
       " 10.249221,\n",
       " 5.507785,\n",
       " 72.97548,\n",
       " -6.47703,\n",
       " 10.37165,\n",
       " 4.370824,\n",
       " 2.0715063,\n",
       " 12.562927,\n",
       " 5.7107677,\n",
       " 6.291709,\n",
       " 13.107989,\n",
       " 12.756445,\n",
       " 3.012161,\n",
       " 4.8254967,\n",
       " 4.955573,\n",
       " -13.752149,\n",
       " -1.4254011,\n",
       " 7.471816,\n",
       " 14.836952,\n",
       " 12.670201,\n",
       " 35.0786,\n",
       " -5.6658287,\n",
       " 14.191192,\n",
       " 3.8983572,\n",
       " -4.1729937,\n",
       " 11.987605,\n",
       " -4.5189667,\n",
       " -5.6740313,\n",
       " -8.121411,\n",
       " 17.303328,\n",
       " -5.0599933,\n",
       " 16.466206,\n",
       " 1.3161134,\n",
       " 4.047477,\n",
       " 12.655325,\n",
       " 5.591178,\n",
       " 11.768306,\n",
       " -8.698204,\n",
       " -6.551793,\n",
       " 11.32689,\n",
       " 2.6654983,\n",
       " 8.623668,\n",
       " 0.9519757,\n",
       " -5.9054174,\n",
       " 8.299073,\n",
       " 5.792384,\n",
       " 2.288009,\n",
       " 5.153116,\n",
       " 17.201353,\n",
       " 7.774087,\n",
       " 6.448456,\n",
       " 1.5774181,\n",
       " 8.177794,\n",
       " 2.495946,\n",
       " 0.78532684,\n",
       " 4.5524163,\n",
       " 3.288077,\n",
       " 40.04243,\n",
       " 6.121372,\n",
       " -7.4852247,\n",
       " -1.8647963,\n",
       " 22.142,\n",
       " 10.072032,\n",
       " 45.370228,\n",
       " 3.4099624,\n",
       " 11.386546,\n",
       " 57.285053,\n",
       " 0.45952067,\n",
       " -1.8795573,\n",
       " 15.540109,\n",
       " 13.561713,\n",
       " 3.465453,\n",
       " 35.646004,\n",
       " 11.3215065,\n",
       " 8.090618,\n",
       " 9.4279585,\n",
       " 5.414773,\n",
       " 8.532768,\n",
       " 7.3500433,\n",
       " 40.903126,\n",
       " 10.058318,\n",
       " 5.903125,\n",
       " 13.4459715,\n",
       " 19.076374,\n",
       " -22.39562,\n",
       " 31.23549,\n",
       " -8.617925,\n",
       " 3.1183193,\n",
       " 11.111703,\n",
       " 6.022338,\n",
       " 28.20296,\n",
       " 3.3611834,\n",
       " 4.831296,\n",
       " 11.506961,\n",
       " -6.313784,\n",
       " 0.2717236,\n",
       " 7.7365847,\n",
       " -7.1922636,\n",
       " 20.306902,\n",
       " 2.3720713,\n",
       " 1.8355817,\n",
       " 20.619514,\n",
       " 2.1423233,\n",
       " 2.8064058,\n",
       " 5.648343,\n",
       " 0.9717587,\n",
       " 6.388388,\n",
       " -1.1673323,\n",
       " 7.6613617,\n",
       " 12.925426,\n",
       " 16.64342,\n",
       " 5.685176,\n",
       " 7.7552786,\n",
       " 4.717625,\n",
       " 11.383717,\n",
       " 4.9263105,\n",
       " 15.565329,\n",
       " 7.4008856,\n",
       " 9.692058,\n",
       " 38.277454,\n",
       " 0.25509915,\n",
       " -5.9613934,\n",
       " 6.294246,\n",
       " 11.989577,\n",
       " 3.168266,\n",
       " 9.89035,\n",
       " 15.331681,\n",
       " 10.153516,\n",
       " 0.48697934,\n",
       " 11.010272,\n",
       " 7.671487,\n",
       " -5.7675753,\n",
       " 22.79054,\n",
       " -2.5293477,\n",
       " 10.758237,\n",
       " -4.3856144,\n",
       " 9.715579,\n",
       " 19.719408,\n",
       " 4.367282,\n",
       " 13.142707,\n",
       " 5.297667,\n",
       " -1.4686471,\n",
       " -10.431518,\n",
       " 8.449483,\n",
       " 4.188755,\n",
       " 14.831741,\n",
       " -7.141862,\n",
       " 8.271712,\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "259.219px",
    "left": "1285.23px",
    "right": "20px",
    "top": "120px",
    "width": "294.774px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
