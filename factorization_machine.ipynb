{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorization Machine using LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import import_ipynb\n",
    "import data_acquisition\n",
    "import feature_engineering\n",
    "\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import recall_at_k\n",
    "from lightfm.evaluation import auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fetch data objects using defined functions\n",
    "\n",
    "# ratings, business, checkin, user, tips = feature_engineering.get_yelp_data()\n",
    "# user = feature_engineering.add_user_features(user, ratings, tips)\n",
    "# business = feature_engineering.add_item_features(business, checkin)\n",
    "# ratings = feature_engineering.add_features_to_ratings(ratings, user, business)\n",
    "# ratings_train, ratings_validation, ratings_test = feature_engineering.train_validation_test_split(years = 1)\n",
    "# ratings_recommend = feature_engineering.user_recommendation_options(ratings_train)\n",
    "\n",
    "# fetch data objects from saved pickle files\n",
    "ratings_train = pickle.load(open(\"data/ratings_train_1_years.pkl\", \"rb\"))\n",
    "ratings_test = pickle.load(open(\"data/ratings_test_1_years.pkl\", \"rb\"))\n",
    "ratings_valid = pickle.load(open(\"data/ratings_validation_1_years.pkl\", \"rb\"))\n",
    "\n",
    "business_df = pickle.load(open(\"data/business_feature_set.pkl\", \"rb\"))\n",
    "user_df = pickle.load(open(\"data/user_feature_set.pkl\", \"rb\"))\n",
    "\n",
    "recommendation_df = pickle.load(open(\"data/ratings_recommendation_list.pkl\", \"rb\"))\n",
    "\n",
    "# formatting dataframe\n",
    "ratings_train = ratings_train[['user_id', 'business_id', 'rating']]\n",
    "ratings_test = ratings_test[['user_id', 'business_id', 'rating']]\n",
    "user_df = user_df.fillna(0)\n",
    "business_df = business_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users Count  (284023, 10)\n",
      "Business Count  (4221, 16)\n",
      "Ratings Train Count  (38146, 3)\n",
      "Ratings Test Count  (6255, 3)\n",
      "Ratings Validation Count  (12510, 29)\n",
      "Ratings Recommendation Pairs  (16532357, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Users Count \", user_df.shape)\n",
    "print(\"Business Count \", business_df.shape)\n",
    "print(\"Ratings Train Count \", ratings_train.shape)\n",
    "print(\"Ratings Test Count \", ratings_test.shape)\n",
    "print(\"Ratings Validation Count \", ratings_valid.shape)\n",
    "print(\"Ratings Recommendation Pairs \", recommendation_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_tupleList(key_col, df):\n",
    "    result = []\n",
    "    for i,row in df.iterrows():\n",
    "        key_val = row[key_col]\n",
    "        feature_dict = {}\n",
    "        for col in df.columns.values:\n",
    "            if col!=key_col:\n",
    "                feature_dict[col] = row[col]\n",
    "        result.append((key_val, feature_dict))\n",
    "    return result\n",
    "\n",
    "def convert_ratings_to_tupleList(df, user_id, business_id, weight_id):\n",
    "    result = []\n",
    "    for i,row in df.iterrows():\n",
    "        row_tuple = (row[user_id], row[business_id], row[weight_id])\n",
    "        result.append(row_tuple)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_map = None\n",
    "business_map = None\n",
    "def convert_to_fm_format(interaction_features, user_features, business_features):\n",
    "    global users_map, business_map\n",
    "    global users_map, business_map\n",
    "    dataset = Dataset(user_identity_features=False, item_identity_features=False)\n",
    "    \n",
    "    # interaction matrix\n",
    "    user_features_list = list(user_features[0][1].keys())\n",
    "    business_features_list = list(business_features[0][1].keys())\n",
    "    \n",
    "    uid_list = (x[0] for x in user_features)\n",
    "    bid_list = (x[0] for x in business_features)\n",
    "    \n",
    "    dataset.fit(uid_list, bid_list, user_features=user_features_list, item_features=business_features_list)\n",
    "    interactions_mat, interactions_weights = dataset.build_interactions(interaction_features)\n",
    "    num_users, num_items = dataset.interactions_shape()\n",
    "\n",
    "    # business features matrix\n",
    "    business_features_mat = dataset.build_item_features(business_features)\n",
    "\n",
    "    # user features matrix\n",
    "    user_features_mat = dataset.build_user_features(user_features)\n",
    "    \n",
    "    users_map = dataset.mapping()[0]\n",
    "    business_map = dataset.mapping()[2]\n",
    "    \n",
    "    return interactions_mat, interactions_weights, business_features_mat, user_features_mat\n",
    "\n",
    "\n",
    "def get_rating_user_business_mat(ratings, user_df, business_df):\n",
    "    uid = set(ratings['user_id'].values)\n",
    "    bid = set(ratings['business_id'].values)\n",
    "    \n",
    "    user_df = user_df[user_df['user_id'].apply(lambda x: x in uid)].reset_index(drop = True)\n",
    "    business_df = business_df[business_df['business_id'].apply(lambda x: x in bid)].reset_index(drop = True)\n",
    "    \n",
    "    user_features = convert_df_to_tupleList('user_id', user_df)\n",
    "    business_features = convert_df_to_tupleList('business_id', business_df)\n",
    "    interaction_features = convert_ratings_to_tupleList(ratings, 'user_id', 'business_id', 'rating')\n",
    "    \n",
    "    return convert_to_fm_format(interaction_features, user_features, business_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Formatted:\n",
      "Ratings Size:  38146 Users Size: 6255 Business Size : 2649\n",
      "Interaction matrix shape:  (6255, 2649)\n",
      "Business matrix shape:  (2649, 30)\n",
      "User matrix shape:  (6255, 32)\n",
      "\n",
      "\n",
      "Test Data Formatted:\n",
      "Ratings Size:  6255 Users Size: 6255 Business Size : 1944\n",
      "Interaction matrix shape:  (6255, 1944)\n",
      "Business matrix shape:  (1944, 30)\n",
      "User matrix shape:  (6255, 32)\n",
      "\n",
      "\n",
      "Validation Data Formatted:\n",
      "Ratings Size:  12510 Users Size: 6255 Business Size : 2309\n",
      "Interaction matrix shape:  (6255, 2309)\n",
      "Business matrix shape:  (2309, 30)\n",
      "User matrix shape:  (6255, 32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data Formatted:\")\n",
    "train_interactions_mat, train_interactions_weights, train_business_features_mat, train_user_features_mat = get_rating_user_business_mat(ratings_train, user_df, business_df)\n",
    "print(\"Interaction matrix shape: \", train_interactions_mat.get_shape())\n",
    "print(\"Business matrix shape: \", train_business_features_mat.get_shape())\n",
    "print(\"User matrix shape: \", train_user_features_mat.get_shape())\n",
    "\n",
    "print(\"\\n\\nTest Data Formatted:\")\n",
    "test_interactions_mat, test_interactions_weights, test_business_features_mat, test_user_features_mat = get_rating_user_business_mat(ratings_test, user_df, business_df)\n",
    "print(\"Interaction matrix shape: \", test_interactions_mat.get_shape())\n",
    "print(\"Business matrix shape: \", test_business_features_mat.get_shape())\n",
    "print(\"User matrix shape: \", test_user_features_mat.get_shape())\n",
    "\n",
    "print(\"\\n\\nValidation Data Formatted:\")\n",
    "valid_interactions_mat, valid_interactions_weights, valid_business_features_mat, valid_user_features_mat = get_rating_user_business_mat(ratings_valid, user_df, business_df)\n",
    "print(\"Interaction matrix shape: \", valid_interactions_mat.get_shape())\n",
    "print(\"Business matrix shape: \", valid_business_features_mat.get_shape())\n",
    "print(\"User matrix shape: \", valid_user_features_mat.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(interactions_mat, user_features_mat, business_features_mat, \n",
    "                interactions_weights, learning_rate_p = 0.05, epochs_p = 30):\n",
    "    \n",
    "    print(\"Learning Rate \",learning_rate_p)\n",
    "    print(\"Epochs \",epochs_p)\n",
    "\n",
    "    model = LightFM(loss='warp', learning_rate=learning_rate_p)\n",
    "    model.fit(interactions_mat, user_features = user_features_mat, item_features = business_features_mat,\n",
    "              sample_weight = interactions_weights, epochs = epochs_p)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(model, interactions_mat, business_features_mat, user_features_mat, k_value=10):\n",
    "    \n",
    "    precision = np.nanmean(precision_at_k(model, interactions_mat, item_features = business_features_mat,\n",
    "                                          user_features = user_features_mat, k = k_value))\n",
    "    \n",
    "    recall = np.nanmean(recall_at_k(model, interactions_mat, item_features = business_features_mat,\n",
    "                                    user_features = user_features_mat, k = k_value))\n",
    "    \n",
    "    auc = np.nanmean(auc_score(model, interactions_mat, item_features = business_features_mat, \n",
    "                               user_features = user_features_mat))\n",
    "    \n",
    "    return precision, recall, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Hyperparameter Tuning\n",
    "\n",
    "1. Tuning for hyperparameter - **learning_rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Using validation Set: \n",
      "\n",
      "Learning Rate  0.01\n",
      "Epochs  30\n",
      "{'learning_rate': 0.01, 'precision': 0.015619505, 'recall': 0.03378351533351603, 'auc': 0.74119234}\n",
      "{'learning_rate': 0.01, 'precision': 0.0069064754, 'recall': 0.034532374100719423, 'auc': 0.71928316} \n",
      "\n",
      "Learning Rate  0.03\n",
      "Epochs  30\n",
      "{'learning_rate': 0.03, 'precision': 0.014068745, 'recall': 0.0299608278129903, 'auc': 0.7420117}\n",
      "{'learning_rate': 0.03, 'precision': 0.0058992803, 'recall': 0.029496402877697843, 'auc': 0.719817} \n",
      "\n",
      "Learning Rate  0.05\n",
      "Epochs  30\n",
      "{'learning_rate': 0.05, 'precision': 0.013573142, 'recall': 0.029276462370722612, 'auc': 0.74226296}\n",
      "{'learning_rate': 0.05, 'precision': 0.0058673057, 'recall': 0.029336530775379697, 'auc': 0.7200129} \n",
      "\n",
      "Learning Rate  0.07\n",
      "Epochs  30\n",
      "{'learning_rate': 0.07, 'precision': 0.013317347, 'recall': 0.028973500876503164, 'auc': 0.74232924}\n",
      "{'learning_rate': 0.07, 'precision': 0.0058832937, 'recall': 0.02941646682653877, 'auc': 0.7200547} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  30\n",
      "{'learning_rate': 0.09, 'precision': 0.013589129, 'recall': 0.02960052405634129, 'auc': 0.7423199}\n",
      "{'learning_rate': 0.09, 'precision': 0.0060911267, 'recall': 0.030455635491606715, 'auc': 0.7200755} \n",
      "\n",
      "Learning Rate  0.11\n",
      "Epochs  30\n",
      "{'learning_rate': 0.11, 'precision': 0.013557155, 'recall': 0.02914284346475702, 'auc': 0.742703}\n",
      "{'learning_rate': 0.11, 'precision': 0.0060271784, 'recall': 0.030135891286970425, 'auc': 0.7203941} \n",
      "\n",
      "Learning Rate  0.13\n",
      "Epochs  30\n",
      "{'learning_rate': 0.13, 'precision': 0.013461232, 'recall': 0.02912321969983378, 'auc': 0.74263906}\n",
      "{'learning_rate': 0.13, 'precision': 0.0059952037, 'recall': 0.02997601918465228, 'auc': 0.72032905} \n",
      "\n",
      "Learning Rate  0.15\n",
      "Epochs  30\n",
      "{'learning_rate': 0.15, 'precision': 0.013637091, 'recall': 0.029415566345393572, 'auc': 0.74288154}\n",
      "{'learning_rate': 0.15, 'precision': 0.0060911267, 'recall': 0.030455635491606715, 'auc': 0.720495} \n",
      "\n",
      "Learning Rate  0.17\n",
      "Epochs  30\n",
      "{'learning_rate': 0.17, 'precision': 0.01370104, 'recall': 0.029547288359915852, 'auc': 0.74288416}\n",
      "{'learning_rate': 0.17, 'precision': 0.006123102, 'recall': 0.03061550759392486, 'auc': 0.7205201} \n",
      "\n",
      "Learning Rate  0.19\n",
      "Epochs  30\n",
      "{'learning_rate': 0.19, 'precision': 0.013717026, 'recall': 0.029546224960708904, 'auc': 0.7428242}\n",
      "{'learning_rate': 0.19, 'precision': 0.0061710635, 'recall': 0.03085531574740208, 'auc': 0.7204839} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_lr = []\n",
    "valid_lr = []\n",
    "print(\"Tuning Using validation Set: \\n\")\n",
    "learning_rates_list = [0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19]\n",
    "\n",
    "for learning_rate in learning_rates_list:\n",
    "    model = train_model(train_interactions_mat, train_user_features_mat, train_business_features_mat, \n",
    "                        train_interactions_weights, learning_rate)\n",
    "    \n",
    "    train_p, train_r, train_auc =  eval_metrics(model, train_interactions_mat, \n",
    "                                                train_business_features_mat, train_user_features_mat)\n",
    "    \n",
    "    # Validation Accuracy\n",
    "    valid_p, valid_r, valid_auc = eval_metrics(model, valid_interactions_mat, \n",
    "                                               valid_business_features_mat, valid_user_features_mat)\n",
    "\n",
    "    tr = {\"learning_rate\": learning_rate, \"precision\": train_p, \"recall\":train_r, \"auc\":train_auc}\n",
    "    te = {\"learning_rate\": learning_rate, \"precision\": valid_p, \"recall\":valid_r, \"auc\":valid_auc}\n",
    "    \n",
    "    print(tr)\n",
    "    print(te, \"\\n\")\n",
    "    \n",
    "    train_lr.append(tr)\n",
    "    valid_lr.append(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Learning parameter found:  0.09\n"
     ]
    }
   ],
   "source": [
    "best_learning_rate = 0.09\n",
    "print(\"Best Learning parameter found: \", best_learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tuning for hyperparameter - **epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Using validation Set: \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  5\n",
      "{'epochs': 0.19, 'precision': 0.014132694, 'recall': 0.03020463178190365, 'auc': 0.7422164}\n",
      "{'epochs': 0.19, 'precision': 0.005963229, 'recall': 0.029816147082334134, 'auc': 0.71997136} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  10\n",
      "{'epochs': 0.19, 'precision': 0.013397283, 'recall': 0.028817774541305973, 'auc': 0.7423761}\n",
      "{'epochs': 0.19, 'precision': 0.0059472425, 'recall': 0.02973621103117506, 'auc': 0.72007865} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  15\n",
      "{'epochs': 0.19, 'precision': 0.013205437, 'recall': 0.02870886116014765, 'auc': 0.74218893}\n",
      "{'epochs': 0.19, 'precision': 0.0058353315, 'recall': 0.029176658673061552, 'auc': 0.7199434} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  20\n",
      "{'epochs': 0.19, 'precision': 0.013413271, 'recall': 0.028833343515046933, 'auc': 0.7423407}\n",
      "{'epochs': 0.19, 'precision': 0.0059472416, 'recall': 0.02973621103117506, 'auc': 0.72007596} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  25\n",
      "{'epochs': 0.19, 'precision': 0.013429256, 'recall': 0.029148731330505728, 'auc': 0.7423228}\n",
      "{'epochs': 0.19, 'precision': 0.0059792167, 'recall': 0.029896083133493206, 'auc': 0.720074} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  30\n",
      "{'epochs': 0.19, 'precision': 0.013573142, 'recall': 0.02926484687213213, 'auc': 0.74270344}\n",
      "{'epochs': 0.19, 'precision': 0.0059952037, 'recall': 0.02997601918465228, 'auc': 0.72037965} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  35\n",
      "{'epochs': 0.19, 'precision': 0.0135091925, 'recall': 0.02922002537217902, 'auc': 0.74259984}\n",
      "{'epochs': 0.19, 'precision': 0.006059153, 'recall': 0.03029576338928857, 'auc': 0.72029567} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  40\n",
      "{'epochs': 0.19, 'precision': 0.01346123, 'recall': 0.029152754086327046, 'auc': 0.74249864}\n",
      "{'epochs': 0.19, 'precision': 0.0060911267, 'recall': 0.030455635491606715, 'auc': 0.7202323} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  45\n",
      "{'epochs': 0.19, 'precision': 0.013573142, 'recall': 0.02922309672246831, 'auc': 0.74265164}\n",
      "{'epochs': 0.19, 'precision': 0.006059153, 'recall': 0.03029576338928857, 'auc': 0.7203348} \n",
      "\n",
      "Learning Rate  0.09\n",
      "Epochs  50\n",
      "{'epochs': 0.19, 'precision': 0.0135251805, 'recall': 0.029182047524004887, 'auc': 0.74265116}\n",
      "{'epochs': 0.19, 'precision': 0.006043166, 'recall': 0.030215827338129497, 'auc': 0.720347} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_epoch = []\n",
    "valid_epoch = []\n",
    "print(\"Tuning Using validation Set: \\n\")\n",
    "epochs_list = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "for epochs in epochs_list:\n",
    "    model = train_model(train_interactions_mat, train_user_features_mat, train_business_features_mat, \n",
    "                        train_interactions_weights, learning_rate_p = best_learning_rate, epochs_p = epochs)\n",
    "    \n",
    "    train_p, train_r, train_auc =  eval_metrics(model, train_interactions_mat, \n",
    "                                                train_business_features_mat, train_user_features_mat)\n",
    "    \n",
    "    # Validation Accuracy\n",
    "    valid_p, valid_r, valid_auc = eval_metrics(model, valid_interactions_mat, \n",
    "                                               valid_business_features_mat, valid_user_features_mat)\n",
    "\n",
    "    tr = {\"epochs\": learning_rate, \"precision\": train_p, \"recall\":train_r, \"auc\":train_auc}\n",
    "    te = {\"epochs\": learning_rate, \"precision\": valid_p, \"recall\":valid_r, \"auc\":valid_auc}\n",
    "    \n",
    "    print(tr)\n",
    "    print(te, \"\\n\")\n",
    "    \n",
    "    train_epoch.append(tr)\n",
    "    valid_epoch.append(te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number of Epochs found:  35\n"
     ]
    }
   ],
   "source": [
    "best_epochs = 35\n",
    "print(\"Best Number of Epochs found: \", best_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Model Training - using learnt best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = train_model(train_interactions_mat, train_user_features_mat, train_business_features_mat, \n",
    "                          train_interactions_weights, learning_rate_p = best_learning_rate, epochs_p = best_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Model Evaluation - on Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision: train 0.013, test 0.003\n",
      "Recall: train 0.029, test 0.026\n",
      "AUC: train 0.74, test 0.676\n"
     ]
    }
   ],
   "source": [
    "# test precision\n",
    "test_p, test_r, test_auc = eval_metrics(model_final, test_interactions_mat, \n",
    "                                        test_business_features_mat, test_user_features_mat)\n",
    "\n",
    "# training precision\n",
    "train_p, train_r, train_auc =  eval_metrics(model_final, train_interactions_mat, \n",
    "                                            train_business_features_mat, train_user_features_mat)\n",
    "\n",
    "print('\\nPrecision: train %.3f, test %.3f' % (train_p, test_p))\n",
    "print('Recall: train %.3f, test %.3f' % (train_r, test_r))\n",
    "print('AUC: train %.2f, test %.3f' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Generating Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_score(model, user_business_df):    \n",
    "    recommendation_score = []\n",
    "    print(\"Number of Pairs for recommendations: \", user_business_df.shape[0])\n",
    "    user_business_df = user_business_df.drop_duplicates()\n",
    "    print(\"Number of unique Pairs for recommendations: \", user_business_df.shape[0])\n",
    "    user_business_df = user_business_df.reset_index(drop=True)\n",
    "\n",
    "    user_business_df['rating'] = 0\n",
    "\n",
    "    for i, row in user_business_df.iterrows():\n",
    "        uid = row['user_id']\n",
    "        bid = row['business_id']\n",
    "        ub_df = user_business_df[i:i+1]\n",
    "\n",
    "        dummy_int_mat, dummy_int_weights, business_features_mat, user_features_mat = get_rating_user_business_mat(ub_df, user_df, business_df)\n",
    "\n",
    "        u_mapped = users_map[uid]\n",
    "        b_mapped = business_map[bid]\n",
    "        predictions = model.predict(u_mapped,\n",
    "                            [b_mapped],\n",
    "                            user_features=user_features_mat,\n",
    "                            item_features=business_features_mat)\n",
    "        recommendation_score.append(predictions[0])\n",
    "    \n",
    "    user_business_df['recommendation_score'] = recommendation_score\n",
    "    return user_business_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_k(x, k):\n",
    "    aa= x.sort_values(by=['recommendation_score'], ascending = False).head(k)\n",
    "    return list(aa['business_id'])\n",
    "\n",
    "def find_top_k_recommendation(user_business_df, k):\n",
    "    df = user_business_df.groupby('user_id').apply(lambda x: find_top_k(x, k)).reset_index(drop = False)\n",
    "    df.columns = ['user_id', 'recommendations']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Pairs for recommendations:  16532357\n",
      "Number of unique Pairs for recommendations:  16532357\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "user_business_df = recommendation_df\n",
    "df_re_score = get_recommendation_score(model, user_business_df)\n",
    "\n",
    "top_k_recommendations_df = find_top_k_recommendation(df_re_score, k)\n",
    "top_k_recommendations_df.to_csv(\"top_k_recommendations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>33d2OBr5yMWMMW_ibYbqIA</td>\n",
       "      <td>[QnTuluWsuNb3aYCl-J9HVQ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SORwHZxyWwR8iv_ZrMICEg</td>\n",
       "      <td>[FUhJLCocwgZEiVn1Wg1KSg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ZL_zmesRw89J8PrsdJg6Uw</td>\n",
       "      <td>[0OdZXIKQypu6vplpxFilsA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iboD-HEmzhLnqAbLYN-Qhw</td>\n",
       "      <td>[FMo1PJTUV5OpyiZlnTM1Rg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>n45NIRpIDhu3iurWXzAVjg</td>\n",
       "      <td>[99kGGQoig4YaRi-52VtqMA]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id           recommendations\n",
       "0  33d2OBr5yMWMMW_ibYbqIA  [QnTuluWsuNb3aYCl-J9HVQ]\n",
       "1  SORwHZxyWwR8iv_ZrMICEg  [FUhJLCocwgZEiVn1Wg1KSg]\n",
       "2  ZL_zmesRw89J8PrsdJg6Uw  [0OdZXIKQypu6vplpxFilsA]\n",
       "3  iboD-HEmzhLnqAbLYN-Qhw  [FMo1PJTUV5OpyiZlnTM1Rg]\n",
       "4  n45NIRpIDhu3iurWXzAVjg  [99kGGQoig4YaRi-52VtqMA]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_recommendations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
